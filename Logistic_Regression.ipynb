{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Theoretical**\n",
        "\n",
        "---\n",
        "###1) What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "\n",
        "->\n",
        "\n",
        "* Logistic Regression is a classification algorithm used to predict the probability that a given input belongs to a particular category, typically binary (e.g., yes/no, spam/not spam).\n",
        "* It uses the sigmoid (logistic) function to map predicted values to a range between 0 and 1, allowing it to output probabilities.\n",
        "* In contrast, Linear Regression is used for regression tasks where the goal is to predict continuous numerical values, such as prices or temperatures, based on input features.\n",
        "* While Linear Regression fits a straight line to the data, Logistic Regression applies a transformation to fit the data into a classification framework.\n",
        "* The key difference lies in their output: Linear Regression predicts numeric values, while Logistic Regression predicts class probabilities.\n",
        "\n",
        "---\n",
        "\n",
        "###2) What is the mathematical equation of Logistic Regression?\n",
        "\n",
        "->\n",
        "\n",
        "The **mathematical equation of Logistic Regression** is based on the **sigmoid (logistic) function**, which converts a linear combination of input features into a probability.\n",
        "\n",
        "\n",
        "### ðŸ”¹ Equation:\n",
        "\n",
        "$$\n",
        "P(Y = 1 \\mid X) = \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "where,\n",
        "\n",
        "$$\n",
        "z = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n\n",
        "$$\n",
        "\n",
        "\n",
        "### ðŸ”¹ Explanation:\n",
        "\n",
        "* $P(Y = 1 \\mid X)$: Probability that the output $Y$ is 1 given input features $X$\n",
        "* $\\beta_0$: Intercept (bias)\n",
        "* $\\beta_1, \\beta_2, ..., \\beta_n$: Coefficients (weights)\n",
        "* $x_1, x_2, ..., x_n$: Input features\n",
        "* $\\sigma(z)$: Sigmoid function to squash values between 0 and 1\n",
        "\n",
        "This probability is then used to classify the input into classes (e.g., if $P > 0.5$, predict class 1; else, class 0).\n",
        "\n",
        "---\n",
        "\n",
        "###3) Why do we use the Sigmoid function in Logistic Regression?\n",
        "\n",
        "->\n",
        "\n",
        "* We use the sigmoid function in logistic regression because it helps convert the output of a linear equation into a value between 0 and 1, which can be interpreted as a probability.\n",
        "* This is useful for classification problems where we want to predict the chance of something happening, like whether an email is spam or not.\n",
        "* The sigmoid function creates a smooth curve and allows us to set a threshold (like 0.5) to decide the final class.\n",
        "* This makes it ideal for turning numeric predictions into clear yes/no decisions.\n",
        "\n",
        "---\n",
        "\n",
        "###4)  What is the cost function of Logistic Regression?\n",
        "\n",
        "->\n",
        "\n",
        "* The cost function of logistic regression is called **log loss** or **binary cross-entropy**.\n",
        "* It measures how well the model's predicted probabilities match the actual outcomes.\n",
        "* If the model predicts a value close to the true label (0 or 1), the cost is low; if it predicts the wrong value with high confidence, the cost is high.\n",
        "* This function helps the model learn by adjusting its parameters to reduce the overall error.\n",
        "* The goal is to minimize this cost so that the model becomes better at making accurate predictions.\n",
        "\n",
        "---\n",
        "\n",
        "###5) What is Regularization in Logistic Regression? Why is it needed?\n",
        "\n",
        "->\n",
        "\n",
        "* Regularization in logistic regression is used to prevent the model from overfitting the training data.\n",
        "* Sometimes, the model tries too hard to fit every detail, which can make it perform poorly on new data.\n",
        "* Regularization fixes this by adding a penalty to the model when it uses large weights or relies too much on certain features.\n",
        "* This keeps the model simpler and helps it focus on the most important patterns, making it work better on unseen data.\n",
        "\n",
        "---\n",
        "\n",
        "###6) Explain the difference between Lasso, Ridge, and Elastic Net regression\n",
        "\n",
        "->\n",
        "\n",
        "\n",
        "* **Ridge Regression** adds a penalty equal to the **sum of the squares of the coefficients** (L2 penalty). It helps shrink the coefficients towards zero but usually doesnâ€™t make them exactly zero. This means it keeps all features but reduces their impact, which helps with multicollinearity and overfitting.\n",
        "\n",
        "* **Lasso Regression** adds a penalty equal to the **sum of the absolute values of the coefficients** (L1 penalty). This can shrink some coefficients all the way to zero, effectively performing **feature selection** by removing less important features from the model.\n",
        "\n",
        "* **Elastic Net Regression** combines both **L1 (Lasso)** and **L2 (Ridge)** penalties. Itâ€™s useful when you want both to shrink coefficients and perform feature selection, especially when you have many correlated features.\n",
        "\n",
        "In short:\n",
        "\n",
        "* Ridge = shrinks coefficients but keeps all features\n",
        "* Lasso = can shrink some coefficients to zero, selecting features\n",
        "* Elastic Net = a mix of both, balancing shrinkage and feature selection\n",
        "\n",
        "---\n",
        "\n",
        "###7) When should we use Elastic Net instead of Lasso or Ridge?\n",
        "\n",
        "->\n",
        "* Elastic Net regression should be used instead of Lasso or Ridge when the dataset contains many correlated features.\n",
        "* While Lasso performs feature selection by shrinking some coefficients to zero, it may arbitrarily select one feature from a group of correlated features and ignore the rest.\n",
        "* Ridge regression, on the other hand, shrinks coefficients of correlated features together but does not perform feature selection.\n",
        "* Elastic Net combines both L1 (Lasso) and L2 (Ridge) penalties, allowing it to both select important features and handle correlated variables effectively.\n",
        "* Therefore, Elastic Net is preferred when there is multicollinearity among features and when a balance between coefficient shrinkage and feature selection is desired.\n",
        "\n",
        "---\n",
        "\n",
        "###8) What is the impact of the regularization parameter (Î») in Logistic Regression?\n",
        "\n",
        "->\n",
        "\n",
        "The regularization parameter $\\lambda$ in logistic regression controls the **strength of the regularization** applied to the model.\n",
        "\n",
        "* When $\\lambda$ is **large**, the regularization penalty is strong, which forces the model coefficients to be smaller. This helps prevent overfitting by simplifying the model but may lead to **underfitting** if too large.\n",
        "* When $\\lambda$ is **small or zero**, there is little to no regularization, so the model can fit the training data more closely, which may cause **overfitting**.\n",
        "\n",
        "In summary, $\\lambda$ balances the trade-off between **bias and variance**: higher values increase bias but reduce variance, and lower values reduce bias but increase variance. Proper tuning of $\\lambda$ is essential for good model performance.\n",
        "\n",
        "---\n",
        "\n",
        "###9) What are the key assumptions of Logistic Regression?\n",
        "\n",
        "->\n",
        "\n",
        "The key assumptions of Logistic Regression are:\n",
        "\n",
        "1. **Binary Outcome**: The dependent variable is binary (has two possible outcomes, like 0 or 1).\n",
        "\n",
        "2. **Independence of Observations**: Each observation is independent of the others.\n",
        "\n",
        "3. **Linearity of Logit**: The log-odds (logit) of the outcome is a linear combination of the input features. This means the relationship between the predictors and the log-odds is linear.\n",
        "\n",
        "4. **No Multicollinearity**: The independent variables should not be highly correlated with each other.\n",
        "\n",
        "5. **Large Sample Size**: Logistic regression requires a reasonably large sample size to provide reliable estimates.\n",
        "\n",
        "These assumptions help ensure the model produces valid and interpretable results.\n",
        "\n",
        "---\n",
        "\n",
        "###10) What are some alternatives to Logistic Regression for classification tasks?\n",
        "\n",
        "->\n",
        "\n",
        "Some common alternatives to Logistic Regression for classification tasks include:\n",
        "\n",
        "1. **Decision Trees** â€“ Models that split data into branches to make decisions based on feature values.\n",
        "\n",
        "2. **Random Forests** â€“ An ensemble of decision trees that improves accuracy and reduces overfitting.\n",
        "\n",
        "3. **Support Vector Machines (SVM)** â€“ Finds the best boundary (hyperplane) that separates classes with maximum margin.\n",
        "\n",
        "4. **K-Nearest Neighbors (KNN)** â€“ Classifies based on the majority class among the nearest neighbors in the feature space.\n",
        "\n",
        "5. **Naive Bayes** â€“ A probabilistic classifier based on Bayesâ€™ theorem assuming feature independence.\n",
        "\n",
        "6. **Neural Networks** â€“ Models inspired by the brain that can capture complex patterns using layers of interconnected nodes.\n",
        "\n",
        "Each alternative has its strengths depending on data size, feature types, and problem complexity.\n",
        "\n",
        "---\n",
        "\n",
        "###11) What are Classification Evaluation Metrics?\n",
        "\n",
        "->\n",
        "\n",
        "**Classification evaluation metrics** are measures used to assess how well a classification model performs. Some key metrics include:\n",
        "\n",
        "1. **Accuracy**: The proportion of correctly predicted instances out of all predictions.\n",
        "\n",
        "   $$\n",
        "   \\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
        "   $$\n",
        "\n",
        "2. **Precision**: The proportion of true positive predictions out of all positive predictions.\n",
        "\n",
        "   $$\n",
        "   \\text{Precision} = \\frac{TP}{TP + FP}\n",
        "   $$\n",
        "\n",
        "3. **Recall (Sensitivity)**: The proportion of true positive predictions out of all actual positives.\n",
        "\n",
        "   $$\n",
        "   \\text{Recall} = \\frac{TP}{TP + FN}\n",
        "   $$\n",
        "\n",
        "4. **F1 Score**: The harmonic mean of precision and recall, balancing both metrics.\n",
        "\n",
        "   $$\n",
        "   F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "   $$\n",
        "\n",
        "5. **ROC Curve and AUC (Area Under Curve)**: ROC plots true positive rate vs. false positive rate; AUC measures the overall ability to distinguish between classes.\n",
        "\n",
        "6. **Confusion Matrix**: A table showing counts of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN).\n",
        "\n",
        "These metrics help evaluate different aspects of a classification modelâ€™s performance, especially in cases of imbalanced data.\n",
        "\n",
        "---\n",
        "\n",
        "###12)  How does class imbalance affect Logistic Regression?\n",
        "\n",
        "->\n",
        "\n",
        "* Class imbalance can significantly affect logistic regression by making the model biased toward the majority class.\n",
        "* When one class has many more examples than the other, the model tends to predict the majority class more often to minimize overall error, leading to poor performance on the minority class.\n",
        "* This results in low recall or precision for the minority class and a misleadingly high accuracy.\n",
        "* To address this, techniques like resampling (oversampling the minority or undersampling the majority), using class weights, or applying specialized evaluation metrics (like F1 score or AUC) are often used to improve the modelâ€™s ability to correctly classify minority class instances.\n",
        "\n",
        "---\n",
        "\n",
        "###13) What is Hyperparameter Tuning in Logistic Regression?\n",
        "\n",
        "->\n",
        "\n",
        "**Hyperparameter tuning** in logistic regression is the process of selecting the best values for parameters that are set **before** training the model and control its behavior. Unlike model parameters (like weights), hyperparameters are not learned from the data directly.\n",
        "\n",
        "In logistic regression, common hyperparameters include:\n",
        "\n",
        "* The **regularization parameter** $\\lambda$ (or C, its inverse), which controls the strength of regularization.\n",
        "* The **type of regularization** used (L1 or L2).\n",
        "* The **solver** or optimization algorithm.\n",
        "\n",
        "Tuning these hyperparameters involves testing different values (using methods like grid search or random search) to find the combination that results in the best model performance on validation data. Proper hyperparameter tuning helps improve accuracy, reduce overfitting, and create a more reliable model.\n",
        "\n",
        "---\n",
        "\n",
        "###14)  What are different solvers in Logistic Regression? Which one should be used?\n",
        "\n",
        "->\n",
        "\n",
        "* In logistic regression, solvers are methods used to find the best model parameters.\n",
        "* Some common solvers are **liblinear**, which works well for small datasets and supports L1 regularization; **lbfgs** and **newton-cg**, which are good for larger datasets but mainly support L2 regularization; and **saga**, which is efficient for very large datasets and supports both L1 and L2 regularization.\n",
        "* If you have a small dataset or want feature selection (L1), use liblinear or saga.\n",
        "* For bigger datasets, lbfgs or saga are usually better choices.\n",
        "* If youâ€™re unsure, starting with lbfgs is a safe option.\n",
        "\n",
        "---\n",
        "\n",
        "###15) How is Logistic Regression extended for multiclass classification?\n",
        "\n",
        "->\n",
        "\n",
        "Logistic Regression is extended for multiclass classification using techniques like **One-vs-Rest (OvR)** or **Softmax Regression (also called Multinomial Logistic Regression)**.\n",
        "\n",
        "* **One-vs-Rest (OvR)**: The model trains one binary classifier per class, where each classifier distinguishes one class from all others. For prediction, it selects the class whose classifier gives the highest probability.\n",
        "\n",
        "* **Softmax Regression**: Instead of predicting just one probability, the model uses the **softmax function** to output probabilities for all classes simultaneously, ensuring they sum to 1. The class with the highest probability is chosen as the prediction.\n",
        "\n",
        "Softmax regression is generally preferred for problems with multiple classes because it models all classes together and considers the relationship between them.\n",
        "\n",
        "---\n",
        "\n",
        "###16)  What are the advantages and disadvantages of Logistic Regression?\n",
        "\n",
        "->\n",
        "\n",
        "**Advantages of Logistic Regression:**\n",
        "\n",
        "1. **Simple and Easy to Implement** â€“ Itâ€™s straightforward to understand and apply.\n",
        "2. **Efficient** â€“ Works well on linearly separable data and runs quickly even on large datasets.\n",
        "3. **Probabilistic Output** â€“ Provides probabilities for class membership, which is useful for decision-making.\n",
        "4. **Interpretability** â€“ Coefficients indicate the influence of each feature on the outcome.\n",
        "5. **Works Well with Few Features** â€“ Performs well when the relationship between features and target is roughly linear.\n",
        "\n",
        "---\n",
        "\n",
        "**Disadvantages of Logistic Regression:**\n",
        "\n",
        "1. **Assumes Linearity** â€“ Assumes a linear relationship between input features and the log-odds, which limits its use on complex, non-linear data.\n",
        "2. **Not Ideal for Complex Relationships** â€“ Struggles when the decision boundary is highly non-linear.\n",
        "3. **Sensitive to Outliers** â€“ Outliers can disproportionately influence the model.\n",
        "4. **Requires Careful Feature Engineering** â€“ May need feature transformations or interaction terms to perform well.\n",
        "5. **Limited to Binary or Multinomial Classification** â€“ Not suitable for more complex tasks like multi-label classification without extensions.\n",
        "\n",
        "---\n",
        "\n",
        "###17)  What are some use cases of Logistic Regression?\n",
        "\n",
        "->\n",
        "\n",
        "Logistic Regression is widely used in many real-world applications, especially for binary classification problems. Some common use cases include:\n",
        "\n",
        "1. **Medical Diagnosis** â€“ Predicting whether a patient has a disease (e.g., diabetes, cancer) based on symptoms and test results.\n",
        "\n",
        "2. **Spam Detection** â€“ Classifying emails as spam or not spam.\n",
        "\n",
        "3. **Customer Churn Prediction** â€“ Predicting whether a customer will leave a service or subscription.\n",
        "\n",
        "4. **Credit Scoring** â€“ Determining if a loan applicant is likely to default or repay.\n",
        "\n",
        "5. **Marketing Campaigns** â€“ Predicting whether a customer will respond to a promotional offer.\n",
        "\n",
        "6. **Fraud Detection** â€“ Identifying fraudulent transactions in banking or insurance.\n",
        "\n",
        "7. **Sentiment Analysis** â€“ Classifying text or reviews as positive or negative.\n",
        "\n",
        "These examples show logistic regressionâ€™s versatility in fields like healthcare, finance, marketing, and more.\n",
        "\n",
        "---\n",
        "\n",
        "###18) What is the difference between Softmax Regression and Logistic Regression?\n",
        "\n",
        "->\n",
        "\n",
        "**Logistic Regression** is mainly used for **binary classification** problems, where the goal is to predict one of two possible classes. It uses the sigmoid function to output a probability between 0 and 1 for the positive class.\n",
        "\n",
        "**Softmax Regression** (also called **Multinomial Logistic Regression**) is a generalization of logistic regression used for **multiclass classification** problems with three or more classes. Instead of using the sigmoid function, it uses the **softmax function** to output a probability distribution across all classes, ensuring the probabilities sum to 1.\n",
        "\n",
        "**In short:**\n",
        "\n",
        "* Logistic Regression â†’ binary outcomes, uses sigmoid function.\n",
        "* Softmax Regression â†’ multiple classes, uses softmax function to predict probabilities for each class simultaneously.\n",
        "\n",
        "---\n",
        "\n",
        "###19)  How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n",
        "\n",
        "->\n",
        "\n",
        "* The choice between One-vs-Rest (OvR) and Softmax for multiclass classification depends on the nature of the problem and the data.\n",
        "* One-vs-Rest involves training separate binary classifiers for each class, making it suitable when classes are well-separated or when the dataset is imbalanced, as it allows focusing on each class individually.\n",
        "* It is also computationally simpler and faster for a large number of classes. * Softmax regression, on the other hand, models all classes simultaneously by estimating probabilities that sum to one, which makes it preferable when classes are mutually exclusive and share overlapping features.\n",
        "* Softmax tends to produce more calibrated probabilities and can capture relationships between classes better.\n",
        "* Therefore, Softmax is generally preferred for balanced and related classes, while OvR is useful for imbalanced or simpler problems.\n",
        "\n",
        "---\n",
        "\n",
        "###20) How do we interpret coefficients in Logistic Regression?\n",
        "\n",
        "->\n",
        "\n",
        "In logistic regression, coefficients represent the effect of each feature on the **log-odds** of the outcome. Specifically, a coefficient shows how much the log-odds of the dependent event (e.g., class = 1) change with a one-unit increase in the feature, holding other features constant.\n",
        "\n",
        "To interpret coefficients more intuitively, we often convert them to **odds ratios** by exponentiating the coefficient ($e^{\\beta}$):\n",
        "\n",
        "* If $e^{\\beta} > 1$, the feature increases the odds of the event happening.\n",
        "* If $e^{\\beta} < 1$, the feature decreases the odds.\n",
        "* If $e^{\\beta} = 1$, the feature has no effect.\n",
        "\n",
        "For example, an odds ratio of 1.5 means the odds of the outcome increase by 50% for every one-unit increase in that feature.\n",
        "\n",
        "This interpretation helps understand how each predictor influences the likelihood of the target event.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jw9rW8OCxQIF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs9gk-FHxKKN",
        "outputId": "55bd687b-df72-4f14-b85d-d1f3725ac79d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "#1) Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset (using Iris dataset for example)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# For simplicity, convert it to a binary classification problem (class 0 vs rest)\n",
        "y_binary = (y == 0).astype(int)\n",
        "\n",
        "# Split data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2)  Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset (using Iris dataset as example)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Convert to binary classification problem (class 0 vs rest)\n",
        "y_binary = (y == 0).astype(int)\n",
        "\n",
        "# Split data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression with L1 regularization\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear')  # 'liblinear' solver supports L1 penalty\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with L1 Regularization: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O87LESc9uRa",
        "outputId": "caebe078-3155-4d1b-8200-ac7d457b29fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L1 Regularization: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3)  Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset (using Iris dataset as example)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Convert to binary classification problem (class 0 vs rest)\n",
        "y_binary = (y == 0).astype(int)\n",
        "\n",
        "# Split data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression with L2 regularization\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs')  # 'lbfgs' solver supports L2 penalty\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with L2 Regularization: {accuracy:.2f}\")\n",
        "\n",
        "# Print model coefficients\n",
        "print(\"Model Coefficients:\", model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLpHu7749_Em",
        "outputId": "0d3019bb-1731-496c-a389-93f5861ae1a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L2 Regularization: 1.00\n",
            "Model Coefficients: [[-0.42762216  0.88771927 -2.21471658 -0.91610036]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4)  Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset (using Iris dataset as example)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Convert to binary classification problem (class 0 vs rest)\n",
        "y_binary = (y == 0).astype(int)\n",
        "\n",
        "# Split data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression with Elastic Net regularization\n",
        "model = LogisticRegression(\n",
        "    penalty='elasticnet',\n",
        "    solver='saga',        # 'saga' solver supports elasticnet penalty\n",
        "    l1_ratio=0.5,         # Balance between L1 and L2 (0 = Ridge, 1 = Lasso)\n",
        "    max_iter=5000         # Increase iterations for convergence\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with Elastic Net Regularization: {accuracy:.2f}\")\n",
        "\n",
        "# Print model coefficients\n",
        "print(\"Model Coefficients:\", model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQkyg9qj-KGG",
        "outputId": "0170cb66-bc6e-41ee-c5d5-9776e8bfce65"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Elastic Net Regularization: 1.00\n",
            "Model Coefficients: [[ 0.          0.91249296 -2.56810367 -0.55436534]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5) Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset (Iris dataset with 3 classes)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression model (no multi_class param here)\n",
        "base_model = LogisticRegression(solver='liblinear', max_iter=500)\n",
        "\n",
        "# Wrap the logistic regression model with OneVsRestClassifier\n",
        "model = OneVsRestClassifier(base_model)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with One-vs-Rest (OvR): {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ6fUstl-dRF",
        "outputId": "2c856bf6-11ad-4704-9ce9-d946e41e6596"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with One-vs-Rest (OvR): 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6) Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy\n",
        "\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "class LogisticRegressionWrapper(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, penalty='l2', C=1.0, l1_ratio=None, max_iter=500, solver='saga'):\n",
        "        self.penalty = penalty\n",
        "        self.C = C\n",
        "        self.l1_ratio = l1_ratio\n",
        "        self.max_iter = max_iter\n",
        "        self.solver = solver\n",
        "        self.model_ = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        kwargs = {\n",
        "            'penalty': self.penalty,\n",
        "            'C': self.C,\n",
        "            'max_iter': self.max_iter,\n",
        "            'solver': self.solver\n",
        "        }\n",
        "        if self.penalty == 'elasticnet':\n",
        "            kwargs['l1_ratio'] = self.l1_ratio\n",
        "        self.model_ = LogisticRegression(**kwargs)\n",
        "        self.model_.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model_.predict(X)\n",
        "\n",
        "    def score(self, X, y):\n",
        "        return self.model_.score(X, y)\n",
        "\n"
      ],
      "metadata": {
        "id": "6AX2HcBd-j-F"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore', message=\".*l1_ratio parameter is only used when penalty is 'elasticnet'.*\")\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegressionWrapper()\n",
        "\n",
        "param_grid = [\n",
        "    {'penalty': ['l1'], 'C': [0.01, 0.1, 1, 10, 100], 'l1_ratio': [None]},\n",
        "    {'penalty': ['l2'], 'C': [0.01, 0.1, 1, 10, 100], 'l1_ratio': [None]},\n",
        "    {'penalty': ['elasticnet'], 'C': [0.01, 0.1, 1, 10, 100], 'l1_ratio': [0, 0.5, 1]}\n",
        "]\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, scoring='accuracy', cv=5, refit=True)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "y_pred = grid_search.best_estimator_.predict(X_test)\n",
        "print(f\"Accuracy with best parameters: {accuracy_score(y_test, y_pred):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMS1a4FfQWDn",
        "outputId": "1e76f966-293e-4386-ba8b-690a4ae85458"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 1, 'l1_ratio': None, 'penalty': 'l1'}\n",
            "Accuracy with best parameters: 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7) Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Initialize Logistic Regression model WITHOUT multi_class parameter\n",
        "model = LogisticRegression(max_iter=500, solver='lbfgs')  # removed multi_class\n",
        "\n",
        "# Initialize Stratified K-Fold with 5 splits\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation and get accuracy scores\n",
        "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "# Print average accuracy\n",
        "print(f\"Average Accuracy from Stratified K-Fold CV: {np.mean(scores):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7svWxFWS-wNN",
        "outputId": "ad02fd5c-257f-4b41-8ca3-a0c143028c3b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy from Stratified K-Fold CV: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8) Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Create and save the Iris dataset as CSV\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "csv_filename = 'iris_dataset.csv'\n",
        "df.to_csv(csv_filename, index=False)\n",
        "print(f\"Dataset saved as '{csv_filename}'.\")\n",
        "\n",
        "# Step 2: Load the dataset from the saved CSV file\n",
        "data = pd.read_csv(csv_filename)\n",
        "\n",
        "# Step 3: Prepare features and target\n",
        "X = data.iloc[:, :-1]  # All columns except target\n",
        "y = data.iloc[:, -1]   # Target column\n",
        "\n",
        "# Step 4: Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Predict and evaluate accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Logistic Regression Accuracy: {accuracy:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQdGzUwP_JNv",
        "outputId": "a11db55b-c73a-497b-fc9f-96c39125af6f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset saved as 'iris_dataset.csv'.\n",
            "Logistic Regression Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#9)  Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define the model\n",
        "model = LogisticRegression(max_iter=1000, solver='saga')  # saga supports all penalties\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = [\n",
        "    {\n",
        "        'penalty': ['l1'],\n",
        "        'C': [0.01, 0.1, 1, 10],\n",
        "        'solver': ['saga'],\n",
        "    },\n",
        "    {\n",
        "        'penalty': ['l2'],\n",
        "        'C': [0.01, 0.1, 1, 10],\n",
        "        'solver': ['lbfgs', 'saga'],  # lbfgs supports only l2\n",
        "    },\n",
        "    {\n",
        "        'penalty': ['elasticnet'],\n",
        "        'C': [0.01, 0.1, 1, 10],\n",
        "        'solver': ['saga'],\n",
        "        'l1_ratio': [0.1, 0.5, 0.9]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Setup GridSearchCV\n",
        "grid = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "\n",
        "# Fit the grid\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Print best params and score\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Score:\", grid.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOjVgTIp_UQW",
        "outputId": "d4d6b20d-1b98-4f79-cf1b-c7831c9e38bb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "Best Parameters: {'C': 10, 'penalty': 'l2', 'solver': 'saga'}\n",
            "Best Score: 0.9666666666666668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#10) Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset (Iris dataset with 3 classes)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize base Logistic Regression model\n",
        "base_model = LogisticRegression(solver='liblinear', max_iter=500)\n",
        "\n",
        "# Wrap the model with One-vs-One classifier\n",
        "ovo_model = OneVsOneClassifier(base_model)\n",
        "\n",
        "# Train the OvO model\n",
        "ovo_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = ovo_model.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy using One-vs-One (OvO) Logistic Regression: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDrwqYTJAo9c",
        "outputId": "84652e8a-1101-4dec-b962-c108de3505b8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy using One-vs-One (OvO) Logistic Regression: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#11) Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load a binary classification dataset (Breast Cancer dataset)\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(solver='liblinear', max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix using seaborn\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
        "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "hG_orc2UQn10",
        "outputId": "643c3bf1-4299-417a-adc4-8228775e46ec"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#12)  Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Load binary classification dataset (Breast Cancer)\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(solver='liblinear', max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall:    {recall:.2f}\")\n",
        "print(f\"F1-Score:  {f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFYUpDYXQ9Tz",
        "outputId": "b83400c5-c871-4adf-8822-a5289683921d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.95\n",
            "Recall:    0.99\n",
            "F1-Score:  0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#13)  Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Create an imbalanced dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2,\n",
        "                           n_redundant=10, n_clusters_per_class=1,\n",
        "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
        "\n",
        "# Check class distribution\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "print(\"Class distribution:\", dict(zip(unique, counts)))\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with class weights\n",
        "model = LogisticRegression(class_weight='balanced', solver='liblinear', max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1Kh0IQORSgr",
        "outputId": "086231de-61b5-42bf-fd3b-159f15a4744d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution: {np.int64(0): np.int64(900), np.int64(1): np.int64(100)}\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98       186\n",
            "           1       0.67      1.00      0.80        14\n",
            "\n",
            "    accuracy                           0.96       200\n",
            "   macro avg       0.83      0.98      0.89       200\n",
            "weighted avg       0.98      0.96      0.97       200\n",
            "\n",
            "Confusion Matrix:\n",
            "[[179   7]\n",
            " [  0  14]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#14)  Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load Titanic dataset from seaborn\n",
        "import seaborn as sns\n",
        "df = sns.load_dataset(\"titanic\")\n",
        "\n",
        "# Select relevant features\n",
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "df = df[features + ['survived']]\n",
        "\n",
        "# Drop rows where target variable is missing\n",
        "df = df.dropna(subset=['survived'])\n",
        "\n",
        "# Handle missing values\n",
        "# Fill missing age and fare with median, embarked with most frequent\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "df[['age', 'fare']] = imputer_num.fit_transform(df[['age', 'fare']])\n",
        "\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "df[['embarked']] = imputer_cat.fit_transform(df[['embarked']])\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoders = {}\n",
        "for col in ['sex', 'embarked']:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Split data into features and target\n",
        "X = df[features]\n",
        "y = df['survived']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5wPbvxmRdB8",
        "outputId": "220687fa-6056-41f1-9db5-f6b1a08b89c8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8100558659217877\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84       105\n",
            "           1       0.79      0.74      0.76        74\n",
            "\n",
            "    accuracy                           0.81       179\n",
            "   macro avg       0.81      0.80      0.80       179\n",
            "weighted avg       0.81      0.81      0.81       179\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#15) Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1. Logistic Regression without scaling\n",
        "model_no_scaling = LogisticRegression(max_iter=500)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "# 2. Logistic Regression with StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=500)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Print results\n",
        "print(f\"Accuracy without scaling: {accuracy_no_scaling:.2f}\")\n",
        "print(f\"Accuracy with standardization: {accuracy_scaled:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9dCuueeRp49",
        "outputId": "5cf899a5-c899-4cdc-d9df-c0ee5d6c78fe"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 1.00\n",
            "Accuracy with standardization: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#16)  Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
        "\n",
        "# Load binary classification dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for ROC AUC\n",
        "y_probs = model.predict_proba(X_test)[:, 1]  # Probability of positive class\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_probs)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
        "\n",
        "# Plot ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})', color='blue')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - Logistic Regression')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "x5GfgQaKTeBq",
        "outputId": "c7baa7b0-d84a-414b-962f-4d04a7534fc2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 1.00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#17) Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train Logistic Regression with C=0.5\n",
        "model = LogisticRegression(C=0.5, max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with C=0.5: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x7LPzg1TqTC",
        "outputId": "68af744d-a8c9-44b5-93be-24cc7a603a62"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with C=0.5: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#18)  Write a Python program to train Logistic Regression and identify important features based on model coefficients\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Get coefficients (for multiclass, it's one row per class)\n",
        "coefficients = model.coef_\n",
        "\n",
        "# Create DataFrame to display feature importance per class\n",
        "coef_df = pd.DataFrame(coefficients.T, index=feature_names, columns=[f\"Class {i}\" for i in range(coefficients.shape[0])])\n",
        "\n",
        "# Calculate mean absolute importance across all classes\n",
        "coef_df['Mean Importance'] = np.mean(np.abs(coef_df.values), axis=1)\n",
        "\n",
        "# Sort by importance\n",
        "sorted_features = coef_df.sort_values(by='Mean Importance', ascending=False)\n",
        "\n",
        "# Display important features\n",
        "print(\"Feature importance based on Logistic Regression coefficients:\\n\")\n",
        "print(sorted_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaWM-GctT2jz",
        "outputId": "b6193d3b-f47f-4abf-c571-4c556a41eb1f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature importance based on Logistic Regression coefficients:\n",
            "\n",
            "                    Class 0   Class 1   Class 2  Mean Importance\n",
            "petal length (cm) -2.375124 -0.213011  2.588136         1.725424\n",
            "petal width (cm)  -0.998746 -0.775748  1.774494         1.182996\n",
            "sepal width (cm)   0.962518 -0.254827 -0.707691         0.641678\n",
            "sepal length (cm) -0.393456  0.508433 -0.114977         0.338955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#19) Write a Python program to train Logistic Regression and evaluate its performance using Cohenâ€™s Kappa Score\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Cohen's Kappa Score\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Cohen's Kappa Score: {kappa:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaWWAX03UCMb",
        "outputId": "b68f87c6-9dd4-434b-b87e-4ca3fede855d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa Score: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#20)  Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "# Generate a binary classification dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10,\n",
        "                           n_classes=2, random_state=42, weights=[0.7, 0.3])\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for the positive class\n",
        "y_scores = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute Precision-Recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "# Compute Average Precision score (area under PR curve)\n",
        "avg_precision = average_precision_score(y_test, y_scores)\n",
        "\n",
        "# Plot Precision-Recall curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, label=f'Logistic Regression (AP = {avg_precision:.2f})')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "ZXneducCUKXj",
        "outputId": "8dd138c2-c3dd-459b-ec2b-186be8301344"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAIjCAYAAAAQgZNYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAaPJJREFUeJzt3Xd4FWX+/vH7JDlppBNSCIHQkRYglAVEUCmC4qKusqKCqFiAn0rWVbBQdBVdFbFjQ3S/rKBYFgVRjKJSlBosQOiElpBAej3Jmd8fmKPHJEBCck4G3q/ryiVn5pmZz8xjws3kmWcshmEYAgAAAEzIw90FAAAAALVFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAVw3rj55psVFxdXo21WrVoli8WiVatW1UtNZjdo0CANGjTI8Xn//v2yWCxasGCB22oCcH4hzAKoNwsWLJDFYnF8+fr6ql27dpo8ebLS09PdXV6DVxEMK748PDwUFham4cOHa926de4ur06kp6frvvvuU4cOHeTv769GjRopISFB//rXv5Sdne3u8gCYgJe7CwBw7nv00UfVsmVLFRcXa/Xq1Xr11Ve1fPly/fLLL/L393dZHW+88YbsdnuNtrnoootUVFQkb2/veqrq9K6//nqNGDFC5eXl2rlzp1555RVdfPHF2rBhg7p06eK2us7Whg0bNGLECOXn5+vGG29UQkKCJGnjxo168skn9d133+nLL790c5UAGjrCLIB6N3z4cPXs2VOSdNttt6lx48aaM2eO/ve//+n666+vcpuCggI1atSoTuuwWq013sbDw0O+vr51WkdN9ejRQzfeeKPj84ABAzR8+HC9+uqreuWVV9xYWe1lZ2frqquukqenp7Zs2aIOHTo4rX/88cf1xhtv1Mmx6uP/JQANB8MMALjcJZdcIknat2+fpJNjWQMCArRnzx6NGDFCgYGBuuGGGyRJdrtdc+fOVadOneTr66vIyEjdcccdysrKqrTfzz//XAMHDlRgYKCCgoLUq1cv/fe//3Wsr2rM7KJFi5SQkODYpkuXLnr++ecd66sbM/vBBx8oISFBfn5+Cg8P14033qjDhw87tak4r8OHD2vUqFEKCAhQkyZNdN9996m8vLzW12/AgAGSpD179jgtz87O1r333qvY2Fj5+PioTZs2euqppyrdjbbb7Xr++efVpUsX+fr6qkmTJrrsssu0ceNGR5u3335bl1xyiSIiIuTj46OOHTvq1VdfrXXNf/baa6/p8OHDmjNnTqUgK0mRkZF6+OGHHZ8tFotmzpxZqV1cXJxuvvlmx+eKoS3ffvutJk6cqIiICDVr1kxLlixxLK+qFovFol9++cWxbMeOHfrb3/6msLAw+fr6qmfPnlq6dOnZnTSAesGdWQAuVxHCGjdu7FhWVlamYcOG6cILL9QzzzzjGH5wxx13aMGCBRo/frzuvvtu7du3Ty+99JK2bNmiNWvWOO62LliwQLfccos6deqkadOmKSQkRFu2bNGKFSs0ZsyYKutYuXKlrr/+el166aV66qmnJEnbt2/XmjVrdM8991Rbf0U9vXr10uzZs5Wenq7nn39ea9as0ZYtWxQSEuJoW15ermHDhqlPnz565pln9NVXX+nZZ59V69atddddd9Xq+u3fv1+SFBoa6lhWWFiogQMH6vDhw7rjjjvUvHlzrV27VtOmTdPRo0c1d+5cR9tbb71VCxYs0PDhw3XbbbeprKxM33//vX744QfHHfRXX31VnTp10pVXXikvLy99+umnmjhxoux2uyZNmlSruv9o6dKl8vPz09/+9rez3ldVJk6cqCZNmmj69OkqKCjQ5ZdfroCAAL3//vsaOHCgU9vFixerU6dO6ty5syTp119/Vf/+/RUTE6OpU6eqUaNGev/99zVq1Ch9+OGHuuqqq+qlZgC1ZABAPXn77bcNScZXX31lZGRkGAcPHjQWLVpkNG7c2PDz8zMOHTpkGIZhjBs3zpBkTJ061Wn777//3pBkLFy40Gn5ihUrnJZnZ2cbgYGBRp8+fYyioiKntna73fHncePGGS1atHB8vueee4ygoCCjrKys2nP45ptvDEnGN998YxiGYZSWlhoRERFG586dnY712WefGZKM6dOnOx1PkvHoo4867bN79+5GQkJCtcessG/fPkOSMWvWLCMjI8NIS0szvv/+e6NXr16GJOODDz5wtH3ssceMRo0aGTt37nTax9SpUw1PT08jNTXVMAzD+Prrrw1Jxt13313peH+8VoWFhZXWDxs2zGjVqpXTsoEDBxoDBw6sVPPbb799ynMLDQ014uPjT9nmjyQZM2bMqLS8RYsWxrhx4xyfK/6fu/DCCyv16/XXX29EREQ4LT969Kjh4eHh1EeXXnqp0aVLF6O4uNixzG63G/369TPatm17xjUDcA2GGQCod4MHD1aTJk0UGxurv//97woICNDHH3+smJgYp3Z/vlP5wQcfKDg4WEOGDFFmZqbjKyEhQQEBAfrmm28knbzDmpeXp6lTp1Ya32qxWKqtKyQkRAUFBVq5cuUZn8vGjRt17NgxTZw40elYl19+uTp06KBly5ZV2ubOO+90+jxgwADt3bv3jI85Y8YMNWnSRFFRURowYIC2b9+uZ5991umu5gcffKABAwYoNDTU6VoNHjxY5eXl+u677yRJH374oSwWi2bMmFHpOH+8Vn5+fo4/5+TkKDMzUwMHDtTevXuVk5NzxrVXJzc3V4GBgWe9n+pMmDBBnp6eTstGjx6tY8eOOQ0ZWbJkiex2u0aPHi1JOnHihL7++mtdd911ysvLc1zH48ePa9iwYdq1a1el4SQA3IthBgDq3csvv6x27drJy8tLkZGRat++vTw8nP8t7eXlpWbNmjkt27Vrl3JychQREVHlfo8dOybp92ELFb8mPlMTJ07U+++/r+HDhysmJkZDhw7Vddddp8suu6zabQ4cOCBJat++faV1HTp00OrVq52WVYxJ/aPQ0FCnMb8ZGRlOY2gDAgIUEBDg+Hz77bfr2muvVXFxsb7++mu98MILlcbc7tq1Sz/99FOlY1X447Vq2rSpwsLCqj1HSVqzZo1mzJihdevWqbCw0GldTk6OgoODT7n96QQFBSkvL++s9nEqLVu2rLTssssuU3BwsBYvXqxLL71U0skhBt26dVO7du0kSbt375ZhGHrkkUf0yCOPVLnvY8eOVfqHGAD3IcwCqHe9e/d2jMWsjo+PT6WAa7fbFRERoYULF1a5TXXB7UxFREQoOTlZX3zxhT7//HN9/vnnevvttzV27Fi98847Z7XvCn++O1iVXr16OUKydPJO7B8fdmrbtq0GDx4sSbriiivk6empqVOn6uKLL3ZcV7vdriFDhuj++++v8hgVYe1M7NmzR5deeqk6dOigOXPmKDY2Vt7e3lq+fLmee+65Gk9vVpUOHTooOTlZpaWlZzXtWXUP0v3xznIFHx8fjRo1Sh9//LFeeeUVpaena82aNXriiSccbSrO7b777tOwYcOq3HebNm1qXS+AukeYBdBgtW7dWl999ZX69+9fZTj5YztJ+uWXX2ocNLy9vTVy5EiNHDlSdrtdEydO1GuvvaZHHnmkyn21aNFCkpSSkuKYlaFCSkqKY31NLFy4UEVFRY7PrVq1OmX7hx56SG+88YYefvhhrVixQtLJa5Cfn+8IvdVp3bq1vvjiC504caLau7OffvqpSkpKtHTpUjVv3tyxvGJYR10YOXKk1q1bpw8//LDa6dn+KDQ0tNJLFEpLS3X06NEaHXf06NF65513lJSUpO3bt8swDMcQA+n3a2+1Wk97LQE0DIyZBdBgXXfddSovL9djjz1WaV1ZWZkj3AwdOlSBgYGaPXu2iouLndoZhlHt/o8fP+702cPDQ127dpUklZSUVLlNz549FRERoXnz5jm1+fzzz7V9+3ZdfvnlZ3Ruf9S/f38NHjzY8XW6MBsSEqI77rhDX3zxhZKTkyWdvFbr1q3TF198Ual9dna2ysrKJEnXXHONDMPQrFmzKrWruFYVd5P/eO1ycnL09ttv1/jcqnPnnXcqOjpa//jHP7Rz585K648dO6Z//etfjs+tW7d2jPut8Prrr9d4irPBgwcrLCxMixcv1uLFi9W7d2+nIQkREREaNGiQXnvttSqDckZGRo2OB6D+cWcWQIM1cOBA3XHHHZo9e7aSk5M1dOhQWa1W7dq1Sx988IGef/55/e1vf1NQUJCee+453XbbberVq5fGjBmj0NBQbd26VYWFhdUOGbjtttt04sQJXXLJJWrWrJkOHDigF198Ud26ddMFF1xQ5TZWq1VPPfWUxo8fr4EDB+r66693TM0VFxenKVOm1Oclcbjnnns0d+5cPfnkk1q0aJH++c9/aunSpbriiit08803KyEhQQUFBfr555+1ZMkS7d+/X+Hh4br44ot100036YUXXtCuXbt02WWXyW636/vvv9fFF1+syZMna+jQoY471nfccYfy8/P1xhtvKCIiosZ3QqsTGhqqjz/+WCNGjFC3bt2c3gC2efNmvffee+rbt6+j/W233aY777xT11xzjYYMGaKtW7fqiy++UHh4eI2Oa7VadfXVV2vRokUqKCjQM888U6nNyy+/rAsvvFBdunTRhAkT1KpVK6Wnp2vdunU6dOiQtm7denYnD6BuuXMqBQDntoppkjZs2HDKduPGjTMaNWpU7frXX3/dSEhIMPz8/IzAwECjS5cuxv33328cOXLEqd3SpUuNfv36GX5+fkZQUJDRu3dv47333nM6zh+n5lqyZIkxdOhQIyIiwvD29jaaN29u3HHHHcbRo0cdbf48NVeFxYsXG927dzd8fHyMsLAw44YbbnBMNXa685oxY4ZxJj9+K6a5evrpp6tcf/PNNxuenp7G7t27DcMwjLy8PGPatGlGmzZtDG9vbyM8PNzo16+f8cwzzxilpaWO7crKyoynn37a6NChg+Ht7W00adLEGD58uLFp0yana9m1a1fD19fXiIuLM5566ilj/vz5hiRj3759jna1nZqrwpEjR4wpU6YY7dq1M3x9fQ1/f38jISHBePzxx42cnBxHu/LycuOBBx4wwsPDDX9/f2PYsGHG7t27q52a61T/z61cudKQZFgsFuPgwYNVttmzZ48xduxYIyoqyrBarUZMTIxxxRVXGEuWLDmj8wLgOhbDOMXv4AAAAIAGjDGzAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEzrvHtpgt1u15EjRxQYGCiLxeLucgAAAPAnhmEoLy9PTZs2lYfHqe+9nndh9siRI4qNjXV3GQAAADiNgwcPqlmzZqdsc96F2cDAQEknL05QUFC9H89ms+nLL790vIYT5kMfmh99aH70obnRf+bn6j7Mzc1VbGysI7edynkXZiuGFgQFBbkszPr7+ysoKIhvYJOiD82PPjQ/+tDc6D/zc1cfnsmQUB4AAwAAgGkRZgEAAGBahFkAAACY1nk3ZhYA4BqGYaisrEzl5eVnvS+bzSYvLy8VFxfXyf7gWvSf+dVHH1qtVnl6ep71fgizAIA6V1paqqNHj6qwsLBO9mcYhqKionTw4EHmCDch+s/86qMPLRaLmjVrpoCAgLPaD2EWAFCn7Ha79u3bJ09PTzVt2lTe3t5n/Zef3W5Xfn6+AgICTjuBOhoe+s/86roPDcNQRkaGDh06pLZt257VHVrCLACgTpWWlsputys2Nlb+/v51sk+73a7S0lL5+voShkyI/jO/+ujDJk2aaP/+/bLZbGcVZvk/CgBQLwgtAE6lroYr8JMGAAAApkWYBQAAgGkRZgEAcJG4uDjNnTu31tsvWLBAISEhdVbPueRsr21N3HTTTXriiSdcciyz+vvf/65nn33WJccizAIAIOnmm2/WqFGj6vUYGzZs0O23335GbasKZ6NHj9bOnTtrffwFCxbIYrHIYrHIw8ND0dHRGj16tFJTU2u9z4aiJtf2bGzdulXLly/X3XffXWnde++9J09PT02aNKnSulWrVjmuvcViUWRkpK655hrt3bu3Xuv94IMP1KFDB/n6+qpLly5avnz5abdZuHCh4uPj5e/vr+joaN1yyy06fvy4U5vs7GxNmjRJ0dHR8vHxUbt27Zz2/fDDD+vxxx9XTk5OnZ/TnxFmAQBwkSZNmpzVDA9+fn6KiIg4qxqCgoJ09OhRHT58WB9++KFSUlJ07bXXntU+z4TNZqvX/Z/ttT1TL774oq699toq50Z96623dP/99+u9995TcXFxldunpKToyJEj+uCDD/Trr79q5MiR9fYiibVr1+r666/Xrbfeqi1btmjUqFEaNWqUfvnll2q3WbNmjcaOHatbb71Vv/76qz744AOtX7/e6R8KpaWlGjJkiPbv368lS5YoJSVFb7zxhmJiYhxtOnfurNatW+v//u//6uXc/ogwCwCod4ZhqLC07Ky+ikrLa7yNYRh1dg7ffvutevfuLR8fH0VHR2vq1KkqKytzrM/Ly9MNN9ygRo0aKTo6Ws8995wGDRqke++919Hmj3dbDcPQzJkz1bx5c/n4+Khp06aOu32DBg3SgQMHNGXKFMedPKnqYQaffvqpevXqJV9fX4WHh+uqq6465XlYLBZFRUUpOjpa/fr106233qr169crNzfX0eZ///ufevToIV9fX7Vq1UqzZs1yOtcdO3bowgsvlK+vrzp27KivvvpKFotFn3zyiSRp//79slgsWrx4sQYOHCh/f3998MEHkqQ333xTF1xwgXx9fdWhQwe98sorjv2WlpZq8uTJio6Olq+vr1q0aKHZs2ef9nr9+dpKUmpqqv76178qICBAQUFBuu6665Senu5YP3PmTHXr1k3/+c9/FBcXp+DgYP39739XXl5etdeuvLxcS5Ys0ciRIyut27dvn9auXaupU6eqXbt2+uijj6rcR0REhKKjo3XRRRdp+vTp2rZtm3bv3l3tMc/G888/r8suu0z//Oc/dcEFF+ixxx5Tjx499NJLL1W7zbp16xQXF6e7775bLVu21IUXXqg77rhDGzZscLSZP3++Tpw4oU8++UT9+/dXXFycBg4cqPj4eKd9jRw5UosWLaqXc/sjt84z+9133+npp5/Wpk2bdPToUX388cen/RXPqlWrlJiYqF9//VWxsbF6+OGHdfPNN7ukXgBA7RTZytVx+hcuP+62R4fJ3/vs/6o7fPiwRowYoZtvvlnvvvuuduzYoQkTJsjX11czZ86UJCUmJmrNmjVaunSpIiMjNX36dG3evFndunWrcp8ffvihnnvuOS1atEidOnVSWlqatm7dKkn66KOPFB8fr9tvv10TJkyotq5ly5bpqquu0kMPPaR3331XpaWlZ/Rr5ArHjh3Txx9/LE9PT8c8n99//73Gjh2rF154QQMGDNCePXscd+VmzJih8vJyjRo1Ss2bN9ePP/6ovLw8/eMf/6hy/1OnTtWzzz6r+Ph42Ww2LVy4UNOnT9dLL72k7t27a8uWLZowYYIaNWqkcePG6YUXXtDSpUv1/vvvq3nz5jp48KAOHjx42uv1Z3a73RFkv/32W5WVlWnSpEkaPXq0Vq1a5Wi3Z88effLJJ/rss8+UlZWl6667Tk8++aQef/zxKvf7008/KScnRz179qy07u2339bll1+u4OBg3XjjjXrrrbc0ZsyYU15/Pz8/SSdDfFUWLlyoO+6445T7+PzzzzVgwIAq161bt06JiYlOy4YNG+b4R0dV+vbtqwcffFDLly/X8OHDdezYMS1ZskTDhw93tFm6dKn69u2rSZMm6X//+5+aNGmiMWPG6IEHHnCaL7Z37956/PHHVVJSIh8fn1Oex9lwa5gtKChQfHy8brnlFl199dWnbb9v3z5dfvnluvPOO7Vw4UIlJSXptttuU3R0tIYNG+aCigEA56NXXnlFsbGxeumll2SxWNShQwcdOXJEDzzwgKZPn66CggK98847+u9//6tLL71U0slw07Rp02r3mZqaqqioKA0ePFhWq1XNmzdX7969JUlhYWHy9PRUYGCgoqKiqt3H448/rr///e+aNWuWY9mf7479WU5OjgICAk7eLf/tdcN33323GjVqJEmaNWuWpk6dqnHjxkmSWrVqpccee0z333+/ZsyYoZUrV2rPnj1atWqVo7bHH39cQ4YMqXSse++9V1dffbXsdrtyc3M1a9YsPfvss46/81u2bKlt27bptdde07hx45Samqq2bdvqwgsvlMViUYsWLc7oev1ZUlKSfv75Z+3bt0+xsbGSpHfffVedOnXShg0b1KtXL0knQ++CBQsUGBgo6eSDXUlJSdWG2QMHDsjT07PSUI+K/bz44ouSTj789I9//EP79u1Ty5Ytq9zX0aNH9cwzzygmJkbt27evss2VV16pPn36VLmuwh9/tf9naWlpioyMdFoWGRmptLS0arfp37+/Fi5cqNGjR6u4uFhlZWUaOXKkXnrpJRUVFUmS9u7dq6+//lo33HCDli9frt27d2vixImy2WyaMWOGY19NmzZVaWmp0tLSnPqyrrk1zA4fPtwp6Z/OvHnz1LJlS8fTcRdccIFWr16t5557rsGG2W1Hc7X1uEWev6bLy6v2b7eA+5SVlZ+2D5uG+KlrsxDXFgaYiJ/VU9serf3PabvdrrzcPAUGBdboZQx+1rr5ubt9+3b17dvXaZL3/v37Kz8/X4cOHVJWVpZsNptTuAoODq42pEjStddeq7lz56pVq1a67LLLNGLECI0cOVJeXmf+V3NycvIp79xWJTAwUJs3b5bNZtPnn3+uhQsXOoW3rVu3as2aNU7LysvLVVxcrMLCQqWkpCg2NtYpZFcXKv94B7OgoEB79uzRrbfe6lRzWVmZgoODJZ18CG/IkCFq3769LrvsMl1xxRUaOnSopJpdr+3btys2NtYRZCWpY8eOCgkJ0fbt2x1hNi4uzhFkJSk6OlrHjh2r9toVFRXJx8en0mT/K1euVEFBgUaMGCFJCg8P15AhQzR//nw99thjTm2bNWvm+IdEfHy8PvzwQ3l7e1d5vMDAQKf6XGHbtm265557NH36dA0bNkxHjx7VP//5T911112aM2eOpJPfjxEREXr99dfl6emphIQEHT58WE8//bRTmK2481zxj6b6YqrX2a5bt06DBw92WjZs2DCn8Uh/VlJSopKSEsfnijFBNput3gejS9Ki9Qf13k5Pzd9Z9a9CYBan78PPJvVV+yjX/tDBman4XnfF9zxOXmfDMGS322W32x3Lfb1q/5iGYVhU5u0pP6tnjd4aZBjGGY+brWj7x5pPta7iz388zz+fc8W2f1xW8TkmJkbbt2/XV199pa+++koTJ07U008/rW+++UZWq7XKbf94HOlkWKjqmNWx2+3y8PBQq1atJEnt27fX7t27deedd+rdd9+VJOXn52vmzJlVjr319vZ2XM9TXYs/12cYhgoKCiRJr732WqW7jZ6enrLb7erWrZv27Nmjzz//XElJSbruuut06aWX6oMPPqjR9aqqxj/WWtHGarVWanOq6xkWFqbCwkIVFxc7BdA333xTJ06ccIS3iv389NNPmjFjhjw8PBz7/PbbbxUUFKSIiAhHUK3ueAsXLtRdd91V5boKy5Ytq3aYQVRUlNLS0pz2n5aWpqioqGqP+cQTT6hfv36OoSOdO3fWSy+9pIEDB+r+++9XYGCgoqOjZbVaZbFYHPtp37690tLSnK5NZmamJKlx48bV9oVhGFW+zrYmP69NFWaru12em5uroqIip/+JKsyePdvp1y8VvvzyS5c89ViYYVHLQJ6zO5cdLpBK7RZ9lrRae0Lr7mET1L2VK1e6u4TzgpeXl6KiopSfn1/tWMDaOtXDOWfLZrOprKzM6UGoCq1atdKnn36qnJwcR5hOSkpSYGCggoKC5OnpKavVqu+++05XXnmlpJO/zt+5c6f69Onj2KfdbldxcbHTMQYOHKiBAwdq7Nix6t27t3744QfFx8fLy8tLBQUFTm2Li4tlGIZjWceOHfXFF1/ommuuOaNz/PP2kjRx4kT16NFDEyZMUHx8vLp27apffvmlyrGa+fn5atasmQ4ePKjdu3c7ft3+7bffSjp55zI3N1f5+fmS5FR/xYNPO3bsqPIBqj/WVPGb2+HDh+tvf/ubDhw4oNDQ0FNerz9e24rxttu2bVOzZs0knXxoLTs7Wy1atFBubq5KSkpUXl5e6fpWDImoSuvWrSWdnAasS5cukqQTJ05o6dKleuutt9ShQwdH2/Lyco0YMUKffPKJBg8e7Lg7GR4eruDg4Er9UJVBgwbpu+++O2Wb6OjoavfTs2dPffHFFxo/frxj2YoVK9SjR49qt8nNzZWXl1el6yKd/MdCXl6eEhIStGTJEmVnZzt+U/Lzzz8rKipKxcXFjvYbN25U06ZN5e3tXeXxSktLVVRUpO+++87pAUOpZndzTRVma2PatGlOg59zc3MVGxuroUOHKigoqN6PP8Rm08qVKzVkyBDHvxxhLrbT9OFfX1mnbUfz1Kt3L13UNtwNFeJ0TteHqFvFxcU6ePCgAgIC5OvrWyf7rPhLNDAwsM7e5/5nVqtVhYWFleb9bNy4se69917NmzdPDz/8sCZNmqSUlBQ99dRTmjJlikJCQhQSEqKxY8dq5syZiomJUUREhGbOnCkPDw/5+Pg4/r7x8PCQr6+vgoKCtGDBApWXl6tPnz7y9/fX//73P/n5+aljx44KCgpSy5YttX79euXl5cnHx0fh4eHy9fWVxWJx7G/WrFkaMmSIOnTooNGjR6usrEyff/657r///irP8c/bSycD8ahRo/Tvf/9bn376qWbOnKkrr7xSrVu31jXXXCMPDw9t3bpVv/76qx577DH99a9/VevWrfX//t//01NPPaW8vDw9+eSTkiR/f38FBQU5pq1q1KiRgoKCHP03c+ZM3XvvvYqIiNCwYcNUUlKijRs3Kjs7W1OmTNFzzz2nqKgode/eXR4eHlq+fLmioqIUGxurd99995TX64/X9sorr1SXLl00ceJEzZkzR2VlZZo8ebIjCEuSj4+PPD09na6Fr6+vPDw8qs0HQUFB6tGjh5KTk9W/f39JJ8dGN27cWOPGjav0/+bw4cO1aNEiXX311Y4baBX/ADoTQUFBpxwTezqJiYm6+OKL9eabb2rEiBFavHixkpOT9eabbzpqePDBB3X48GG98847kqRRo0bpjjvu0MKFCx3DDB566CH16tVL0dHRCgwM1D333KM333xT06dP1+TJk7Vr1y4999xz+n//7/85ndvGjRs1bNiwas+3uLhYfn5+uuiiiyr9rDhd0HdiNBCSjI8//viUbQYMGGDcc889Tsvmz59vBAUFnfFxcnJyDElGTk5OLaqsudLSUuOTTz4xSktLXXI81L3T9eGI578zWjzwmfHNjnQXV4YzxfehaxUVFRnbtm0zioqK6myf5eXlRlZWllFeXl5n+/yzcePGGZIqfd16662GYRjGqlWrjF69ehne3t5GVFSU8cADDxg2m82xfW5urjFmzBjD39/fiIqKMubMmWP07t3bmDp1qqNNixYtjOeee84wDMP4+OOPjT59+hhBQUFGo0aNjL/85S/GV1995Wi7bt06o2vXroaPj49R8df122+/bQQHBzvV/eGHHxrdunUzvL29jfDwcOPqq6+u9hyr2r7iWJKMH3/80TAMw1ixYoXRr18/w8/PzwgKCjJ69+5tvP76647227dvN/r37294e3sbHTp0MD799FNDkrFixQrDMAxj3759hiRjy5YthmE499/ChQsd9YaGhhoXXXSR8dFHHxmGYRivv/660a1bN6NRo0ZGUFCQcemllxqbN28+o+v1x2trGIZx4MAB48orrzQaNWpkBAYGGtdee62RlpbmWD9jxgwjPj7e6To899xzRosWLaq9foZhGK+88orxl7/8xfG5S5cuxsSJE6tsu3jxYsPb29vIyMgwvvnmG0OSkZWVdcr917X333/faNeuneHt7W106tTJWLZsmdP6cePGGQMHDnRa9sILLxgdO3Y0/Pz8jOjoaOOGG24wUlNTnb4H165da/Tp08fw8fExWrVqZTz++ONGWVmZYx9FRUVGcHCwsW7dumprO9XPiprkNVOF2fvvv9/o3Lmz07Lrr7/eGDZs2BkfhzCLmiLMmh/fh65l1jBb1/Lz843g4GDjzTffdHcp9W716tWGJGP37t1Vrjdj/1WnsLDQiI2NNdauXevuUlyqpn34yiuvGEOGDDllm7oKs24dZpCfn+80UfC+ffuUnJyssLAwNW/eXNOmTdPhw4cdg9LvvPNOvfTSS7r//vt1yy236Ouvv9b777+vZcuWuesUAACQJG3ZskU7duxQ7969lZOTo0cffVSS9Ne//tXNldW9jz/+WAEBAWrbtq12796te+65R/3793eMKT2X+fn56d1333U83ISqWa1Wx1Rl9c2tYXbjxo26+OKLHZ8rxraOGzdOCxYs0NGjR53eF92yZUstW7ZMU6ZM0fPPP69mzZrpzTffbLDTcgEAzi/PPPOMUlJS5O3trYSEBH3//fcKDz/3xtLn5eXpgQceUGpqqsLDwzV48GDHtJnng0GDBrm7hAbvtttuc9mx3BpmBw0adMopUxYsWFDlNlu2bKnHqgAAqLnu3btr06ZN7i7DJcaOHauxY8e6uwxAksScUQAAADAtwiwAoF6c6jdvAFBXPyMIswCAOlUxl299v8ISgLlVvFTlz2//qqlz/qUJAADX8vT0VEhIiOMd9/7+/mf9ogO73a7S0lIVFxc73jgE86D/zK+u+9ButysjI0P+/v7y8jq7OEqYBQDUuaioKElyBNqzZRiG47Xl9fUGMNQf+s/86qMPPTw81Lx587PeH2EWAFDnLBaLoqOjFRERIZvNdtb7s9ls+u6773TRRRfxSmITov/Mrz760Nvbu07u8hJmAQD1xtPT86zHw1Xsp6ysTL6+voQhE6L/zK8h9yEDVwAAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApuXl7gIAmJNhGDpRUKq9mQU6llui/m0aK8Tf291lAQDOM4RZAKdUbCvXgeOF2puRr72ZBdqTka99mQXam1GgnCKbo931vWM1++qubqwUAHA+IswCkGEYSsst1r6MAu3JLDgZXDMKtDczX4eyimQYVW9nsUgB3l7KKylTRl6Ja4sGAECEWeC8YhiGMvNLlZKWp5T0PO1My9OO9DztTs9TQWl5tdsF+nqpVZMAtQ5vpFZNGqlVkwC1atJIcY0b6X/Jh/XAhz+78CwAAPgdYRY4R5WW2bUzPU/bjuRq29FcR4A9UVBaZXtPD4tahPmr5R8Da/jJ/4YHeMtisbj4DAAAOD3CLHAOyC8p07Yjufr1SI5+PZKrbUdytetYnmzllccHWCxSXONGahcZoPZRQWofGaj2UQFqHtZI3l5McAIAMBfCLGAypWV27UjL1daD2Uo+mKOth7K1JyO/ynGtQb5e6tQ0WJ2aBqlD9Mng2iYiQH7enq4vHACAekCYBRowwzB08ESRNqWe0NaDOUo+mK1tR3JVWm6v1DY62Fcdo4PUqWmQOv4WYJuF+jE8AABwTiPMAg1Iud3Q9qO52rj/hDYcyNLG/SeUnlt5loAQf6vim4UoPjZE3WKD1bVZiMIDfNxQMQAA7kWYBdyotMyu5IPZ+mHvcW3Yf0JbUrOVX1Lm1MbqaVHnmGB1jw1VfGywusWGqHmYP3dcAQAQYRZwKbvd0LajuVq7J1Nrdh/X+n0nVGRznhIr0MdLCXGh6hUXpp4tQhUfGyJfK2NcAQCoCmEWqGcHTxTq250ZWrsnU+v2HFdWoc1pfXiAt/7SqrH6tAxTz7gwtYsMlKcHd10BADgThFmgjpWV27U5NVtJO9L1zY5j2pme77S+kben+rRqrH6tG+vCtuFqHxnIkAEAAGqJMAvUkVUpGfpo82F9uzNDOUW/33319LAooXmoLmwbrv5tGqtrsxBZPZnPFQCAukCYBerIgrX7HX8O8bdqULsmuuSCSA1s20TB/lb3FQYAwDmMMAucpa7NQvTrkVx1iArUJR0idEmHCHVvHsq4VwAAXIAwC5ylJ67qrIcuv0ABPnw7AQDgagzcA86SxWIhyAIA4Cb8DQzAdAzD0JGcYv1yOEe/HM5RSlqehnaK0t8Smrm7NACAixFmATRohmHoUFaRfjmco59/+/r1SK5OFJQ6tfv5cA5hFgDOQ4RZAA1KdmGpth7K0daD2Uo+mK2tB7N1/E/BVZK8PCxqGxmopsG+StpxTGV2ww3VAgDcjTALwG3Kyu3afjRPmw6cOBlcD+VoX2ZBpXZeHha1jwpUl5hgdY4JVpeYYLWPCpSv1VPbj+YqaccxN1QPAGgICLMAXCanyKbNqVnafCBLG/dnKflgtops5ZXaxTX2V3xsiLrFhig+NkQdo4Pka/V0Q8UAgIaOMAug3qTlFOvHfcf1474T2rj/hHYdy5fxp9EAQb5e6t48VD2ah6pb8xB1jQlWaCNv9xQMADAdwiyAOnM4u0g/7j2uH/ee0A/7juvA8cJKbeIa+6tHi1D1bBGmnnGhatMkQB68YAIAUEuEWQB14usdx/TV9q+dlnlYpE5Ng9WnZZh6xoUpoUWomgT6uKlCAMC5iDAL4KyENToZTu2G5OlhUeeYYP2lZZj6tDoZYIN8rW6uEABwLiPMAjgrl3SI0IvXd1eQn1UJLUJ5GxoAwKX4WwfAWfH0sGhkfFN3lwEAOE95uLsAAAAAoLYIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtt4fZl19+WXFxcfL19VWfPn20fv36atvabDY9+uijat26tXx9fRUfH68VK1a4sFoAAAA0JG4Ns4sXL1ZiYqJmzJihzZs3Kz4+XsOGDdOxY8eqbP/www/rtdde04svvqht27bpzjvv1FVXXaUtW7a4uHIAAAA0BG4Ns3PmzNGECRM0fvx4dezYUfPmzZO/v7/mz59fZfv//Oc/evDBBzVixAi1atVKd911l0aMGKFnn33WxZUDAACgIXDbG8BKS0u1adMmTZs2zbHMw8NDgwcP1rp166rcpqSkRL6+vk7L/Pz8tHr16mqPU1JSopKSEsfn3NxcSSeHLNhstrM5hTNScQxXHAv1gz5s2MrKyk7+wTCq7aPzsQ8Nw9Ch7CL9dChXPx3KUXFZue4f2k6NTPq64fOxD88l9J/5uboPa3Ict/1Uy8zMVHl5uSIjI52WR0ZGaseOHVVuM2zYMM2ZM0cXXXSRWrduraSkJH300UcqLy+v9jizZ8/WrFmzKi3/8ssv5e/vf3YnUQMrV6502bFQP+jDhulwgSR5qaSkRMuXLz9l23O5D/NtUmq+RQfyK/5rUUGZxamNNeuAeoQbbqqwbpzLfXg+oP/Mz1V9WFhYeMZtTfVP9Oeff14TJkxQhw4dZLFY1Lp1a40fP77aYQmSNG3aNCUmJjo+5+bmKjY2VkOHDlVQUFC912yz2bRy5UoNGTJEVqu13o+HukcfNmw70vL075/WycfHRyNGDKqyzbnWh0Wl5dp2NFc/Hc7V1kM5+ulQjg5mFVVqZ/W06ILoQB3NLlZGfqk6dumqEd1j3FDx2TvX+vB8Q/+Zn6v7sOI36WfCbWE2PDxcnp6eSk9Pd1qenp6uqKioKrdp0qSJPvnkExUXF+v48eNq2rSppk6dqlatWlV7HB8fH/n4+FRabrVaXfoN5erjoe7Rhw2Tl9dvP8YsltP2jxn70G43tCcjX5tTs5R8MEdbD2YrJT1P5fbKd1hbN2mk+NgQdYsNUXyzEHWIDpSPl6dufnu9VqVkyNPTy3Tn/2dm7EP8jv4zP1f1YU2O4bYw6+3trYSEBCUlJWnUqFGSJLvdrqSkJE2ePPmU2/r6+iomJkY2m00ffvihrrvuOhdUDAD1r6SsXL8cztXG/Se0Yf8JbTyQpezCymPHmgT6qNtvwbVbbIg6xwQr2I+QAOD849ZhBomJiRo3bpx69uyp3r17a+7cuSooKND48eMlSWPHjlVMTIxmz54tSfrxxx91+PBhdevWTYcPH9bMmTNlt9t1//33u/M0AKDWcops2pya9Vt4zdLWg9kqKbM7tfG1evwWWkPVLTZY8bEhigrylcViqWavAHD+cGuYHT16tDIyMjR9+nSlpaWpW7duWrFiheOhsNTUVHl4/D57WHFxsR5++GHt3btXAQEBGjFihP7zn/8oJCTETWcAADVzJLvo5B3X/VnasP+EUtLzZPxpxEDjRt7qGReqXnFh6hkXpk5Ng2T1dPs7bgCgQXL7A2CTJ0+udljBqlWrnD4PHDhQ27Ztc0FVAHD2DMPQvswCrdt7XOv3nQywh7MrP6jVMryReraoCK+hahneiLuuAHCG3B5mAeBccvBEodbtOa61ezK1bu9xpeeWOK339LCoU9Mg9YoLU6+4UCW0CFOTwMoPqQIAzgxhFgDOwrG8Yq3Znam1u49r7Z7jle68ent6qHvzEP2lVWP1bhmmbrEhpn1xwR/lFNm09WC2tqRmK/lgljLyS/TEVV3UtVmIu0sDcJ4x/09UAHChotJy/bjvuFbvytTq3ZnakZbntN7Lw6L42BD1a91YfVs1Vo8WofK1erqp2rpRVm5XSnreb8E1W1tSs7Qno6BSuxW/pBFmAbgcYRYATsFuN7TtaK6+3Zmh1bsytelAlkrLf59twGKROjUNUv824erXOlw9W4Sa/s5rem6xtqRmactvd15/PpSjIlvlNy02D/NX9+YhOniiUJtTs2Xud4sBMCtz/8QFgHqQU2jTd7sytColQ9/uzFBmvvO415gQP13YJlwXtg1X/zbhCmvk7aZKz15pmV0/H87R5gNZ2nIwS8mp2TqSU1ypXaCPl+JjQ9S9+e9z2zYOODnW97HPtmlzaraLKweAkwizAM57druhX4/kalXKMa3amaEtqVn64wu2Gnl7ql+bcA1oG64L24SberaBnCKbNh/IcryQoap5bT0sUvuoIHX7Lbx2jw1R6yYB8vAw5zkDOLcRZgGcl4pKy7Vmd6a+2p6upB3HlJHnfPe1XWSABrWP0KD2TdSzRZi8vcw/z+vs5dv1zyVbK81rG9bIWwktQtWjeai6xYaoa7NgUw2VKCu3Ky23WE2D/QjcwHnIPD+tAOAsZeSV6Ps9R7Vy2zGt3p2hYtvvdyT9vT3Vv024BrVvokHtIxQT4ufGSutWwG/B9HhBqSSpVXgjJZh0XlvDMHTgeIGSD2brp0M52nowW78cyVGxza6b+8Vp5pWd3F0iABcjzAI4p+3JyNfyrYe15GdPHVj3rdO6mBA/XXpBhAZfEKk+rcLk42XuWQeqkziknTpEBapNRKB6xoUqPMA889oeyyvWTwdztPnACX29zUMzklcpu8hWZdtdx/KqXA7g3EaYBXBOMQxDO9Ly9PkvaVrxy1HtTM//bc3JO49dmwVr8AWRGnxBpC6IDjTNHcmz0apJgCZf0tbdZZxWbrFNvxzK0dbf7rj+dOjPD6N5SLLJ29NDHZsGKb5ZsOJjQ3Q0p1hPf5HirrIBuBlhFsA5odhWric/36EVvxzV/uOFjuVeHhb1bRWmaPsx3X3NxWrWONCNVaKC3W5ob2a+Nh3I0qYDWdqcmq09GfmVxvNaLFLbiAB1iQmSR9ZBjRnWX52ahTqNYf5f8mEXVw+gISHMAjgn5BWXad63eyRJ3l4euqhtEw3vHKXBF0TK3yotX75ckUG+bq7y/FVUWq7kg9nanFoRXrOUXVh5uECzUD/FNwtRfGywujYLUeeYYAX4eMlms2n58lR1jgmS9Rx4GA9A3SHMAjC16GBfBfp6qdxu6OL2Ebqsc5Qu7hDheOhJkmy2qsdYov4czSnSpgNZ2rj/ZHDddiRXZXbn266+Vg/FNwv5fSaF5iGmGs8LoGEgzAIwtRB/b/0w7VJ5elhM/9pYs9u0P0v/770t2rT/RJUvXogK8lVCXKgSmocqoUWoOjYNktWzYd5lTc8t/m3cbo62HsrWjrQ8XdU9Rg+OuMDdpQH4E8IsANMz05yo57L1+084/uzpYdEF0YHq2SJMPVqcDK9Ng30b5AN3OYU2/XT496m+th7KVnpuSaV2S5OPEGaBBoi/AQAAZ+WyzlFavStT0SG+J++6xoUqvllIg/xHRlFpuX49cnLGhJ8OZWvrwWynBwYreFikthGBio8NVqi/t177bq8bqgVwJhreTxoAgKn0igvTF1MucncZldjthvZk5Gtzapa2pGYr+WC2dh3LV/mfxu5KUvMwf8XHhii+2ckHzzo1DXKE8V8O5xBmgQaMMAsAOCcUlZbrm5Rj2pKarS2pWUpOzVZeSVmldk0CfU7OUdssRF1jQ9Q1JlihjbzdUDGAukCYBQCcEzanZmv82xuclvlZPdW1WbC6NQ9R99hQxccGKyqoYY7dBVA7hFkAgKm1bhLg+HOr8EYng2vzUHWPDVGHqEB5NdAZEwDUDcIsAMDUOscE68cHL5W3pwfDBYDzEGEWAGB6vN0NOH/xuxcAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGl5ubsAAADOR8W2cv10KEcb9p/Q5gNZ6tQ0SIlD27u7LElSWbldO9PzlXwwW1tSs5R8MFuStPiOvgpr5O3e4oA/IcwCAOACucU2bTqQpQ37TmjD/hPaeihHpWV2x/qkHcd016A28vP2dHltaTnFjtC65WC2fj6UoyJbeaV2mw5kaUjHSJfXB5wKYRYAgHqQkVeiDftPaP1v4XX70VzZDec24QE+6tE8RF9uS5ck2Q2jij3VrcLSMv10KEfJB7OVnJqt5IPZSsstrtQu0MdLXWOD1S02REu3HtHBE0X1XhtQG4RZAADOkmEYSj1R6AiuG/ZnaV9mQaV2zcP81SsuTH1ahqlXyzDFNfZXSZldHR5ZUW917css0KYDWdr8W3BNSascqj0sUoeoIHVrHqJusSHqHhui1k0C5OFhkSSt3XOcMIsGizALAEANGYahA8cL9cPe41q397h+2Htc6bklTm0sFql9ZKB6twxTr7gw9W4Zpsgg33qtq9hWrl8O52jjgayTAfZAlo4XlFZqFx3sq26xIY6vLs2C5e9NJIA58X8uAABnoLTcrsUbUvXD3hNat+d4pV/NWz0t6tos5LfgGqqE5mEK9rfWa03H80u08bfQuvFAln4+lKPScrtTG28vD8U3C1aPFqHqHhuq7s1D6j1UA65EmAUA4AycKCjVAx/+7Phs9bSoe2yo/tIqTH9p3Vg9mofK11p/D2/Z7Yb2ZOQ77rpuOlD1UIbwAG8ltAhVzxZhSogLVaemQfLxcv1DZYCrEGYBADiF5o39FexnVWFpmeKbhahv68b6S6uT4bU+Zx6wldv18+Ecbdh38iGyjQeylFNkq9SuXWSAElqEqWeLUCW0CFWLxv6yWCz1VhfQ0BBmAQA4hSBfqzY8NFjldqPep836cd9x/XwoV+v3H9fmA9mVpsfytXqoW2yI485rj+ah9T6UAWjoCLMAAJyGt5drXph5y4KNTp9D/K2/z34QF6aOTYNk9eTlncAfEWYBAHAjb08PNQv106GsIkUG+ah3y8bq3fJkgG3zh+mxAFSNMAsAgBt5eFj0xb0XKauwVDEhfox3BWqIMAsAgJs18vFSI59z76/ksnK7UtLztGFvpjYetuji0nJZrYzxRd06975zAACAW+QU2rT54Ml5bzenZik5NVsFpRUPsXlq0LZ0/a1XC7fWiHMPYRYAANSY3W5ob2aBNle8bSw1S7uO5VdqF+DjJYtFyisuU35peRV7As4OYRYAAJyRnw9lKyUtV5tTs7U5NUvZhZXnvW0Z3kjdm5+cPiyhRajaRgRq4v9t1BfbjrmhYpwPCLMAAOCMvPD1bqfPPl4eim8Woh6/BdcezUPUOMDHTdXhfOX2yepefvllxcXFydfXV3369NH69etP2X7u3Llq3769/Pz8FBsbqylTpqi4uPiU2wAAgNqLbxYiSWoa7KvLu0Zr+hUd9b9J/fXzzGF6/86+mjq8g4Z0jCTIwi3cemd28eLFSkxM1Lx589SnTx/NnTtXw4YNU0pKiiIiIiq1/+9//6upU6dq/vz56tevn3bu3Kmbb75ZFotFc+bMccMZAABw7pt5ZSclDm2nIN+6m4kgp8im5IPZJ8fbHshSVmGpnv97N7WJCKyzY+D84NYwO2fOHE2YMEHjx4+XJM2bN0/Lli3T/PnzNXXq1Ert165dq/79+2vMmDGSpLi4OF1//fX68ccfXVo3AADnm7oIsuv3nVBKer42H8jWzmN5Mgzn9UnbjxFmUWNuC7OlpaXatGmTpk2b5ljm4eGhwYMHa926dVVu069fP/3f//2f1q9fr969e2vv3r1avny5brrppmqPU1JSopKSEsfn3NxcSZLNZpPNVnngel2rOIYrjoX6QR+aH31ofvShuRm/pdblv6Q7LW8e5qcesSHaeSxf247mqay8nD5uoFz9PViT47gtzGZmZqq8vFyRkZFOyyMjI7Vjx44qtxkzZowyMzN14YUXyjAMlZWV6c4779SDDz5Y7XFmz56tWbNmVVr+5Zdfyt/f/+xOogZWrlzpsmOhftCH5kcfmh99aE5NbBYFWD0U4SvFBRpqGWgoLsBQkHeepDwdKfOQ5KGUHTu0PG+7u8vFKbjqe7CwsPCM25pqNoNVq1bpiSee0CuvvKI+ffpo9+7duueee/TYY4/pkUceqXKbadOmKTEx0fE5NzdXsbGxGjp0qIKCguq9ZpvNppUrV2rIkCG89cSk6EPzow/Njz40tyE2m3qfov++/egXrc84ovYdOmjEgJZuqBCn4+rvwYrfpJ8Jt4XZ8PBweXp6Kj3d+VcO6enpioqKqnKbRx55RDfddJNuu+02SVKXLl1UUFCg22+/XQ899JA8PCpPzuDj4yMfn8pPV1qtVpf+QHT18VD36EPzow/Njz40t+r6r+Lvb09PT/q3gXPV92BNjuG2qbm8vb2VkJCgpKQkxzK73a6kpCT17du3ym0KCwsrBVZPT09Jv4/HAQAAwPnDrcMMEhMTNW7cOPXs2VO9e/fW3LlzVVBQ4JjdYOzYsYqJidHs2bMlSSNHjtScOXPUvXt3xzCDRx55RCNHjnSEWgAAAJw/3BpmR48erYyMDE2fPl1paWnq1q2bVqxY4XgoLDU11elO7MMPPyyLxaKHH35Yhw8fVpMmTTRy5Eg9/vjj7joFAAAAuJHbHwCbPHmyJk+eXOW6VatWOX328vLSjBkzNGPGDBdUBgAAgIbO7a+zBQAAqK2CkjKt2Z2p9zceVE4Rc9Sej9x+ZxYAAOBMHcsr1qb9WdqwP0sb9p/QtqO5KreffAg8LadYd1/a1s0VwtUIswAAoEEyDEN7Mwu0cf8JbdifpY37T2j/8cqT6Xt7eqi03K4TBaVuqBLuRpgFAAANgq3Mri2pWdr4213XjQeyKgVUi0VqHxmoXnFh6hkXqp5xYXrvx1S99M1uN1UNdyPMAgCABuHZlTv17MqdTst8vDwUHxuiXr8F1x7NQxXsx4sV8DvCLAAAcKvIoN/f1Bnib1XPFmGO8No5Jkg+XrWbS95WbtevR3K1cf8JpZ4o1Lh+cWrdJKCuykYDQZgFAABuddegNurRPFQtGvurVXiAPDwstdpPYWmZvtuZ4Rhjm3wwW0W2csd6u2HoX6O61FXZaCAIswAAwK0CfLx06QWRZ72f9zce0vsbDzktC/G3KsDHS4eyilRis5/1MdDwEGYBAICpxYb5Of7cPMz/5INhvw1VaN0kQK99t1dPrdjhxgpRnwizAADA1K7p0Uwdo4MVGeSjiCBfd5cDFyPMAgAAU/Py9FCXZsHuLgNuwutsAQAAYFqEWQAAAJgWYRYAAACmRZgFAACAaRFmAQAAYFqEWQAAAJgWYRYAAACmRZgFAACAaRFmAQAAYFqEWQAAAJgWYRYAAACmRZgFAACAaRFmAQAAYFqEWQAAAJgWYRYAAACmRZgFAACAaRFmAQAAYFqEWQAAAJgWYRYAAACmRZgFAACAaRFmAQAAYFqEWQAAAJgWYRYAAACmRZgFAACAaRFmAQAAYFqEWQAAAJgWYRYAAACmRZgFAACAaRFmAQAAYFqEWQAAAJgWYRYAAACmRZgFAACAaRFmAQAAYFqEWQAAAJgWYRYAAACm5eXuAgAAAMyo3G5o25Fcrd6dqV8O5+jans00qH2Eu8s679QqzJaXl2vBggVKSkrSsWPHZLfbndZ//fXXdVIcAABAQ2EYhg4cL9Tq3ZlasztTa/ccV06RzbE+I7+EMOsGtQqz99xzjxYsWKDLL79cnTt3lsViqeu6AAAA3C4zv+RkcN19XKt3Z+pwdpHT+kAfL8WE+mlHWp7Kyu3V7AX1qVZhdtGiRXr//fc1YsSIuq4HAADAbQpKyrR+/wmt2ZWp1bsztSMtz2m91dOiHs1DdWGbcPVvG66uMcH6escx3f6fTW6qGLUKs97e3mrTpk1d1wIAAOBS5XZDWw9la/Vv4XVLapZs5YZTm47RQerfprH6twlX75Zh8vfmkaOGpFa98Y9//EPPP/+8XnrpJYYYAAAAUzmcXaTvdmbo+10ZWr0rU7nFZU7rY0L8NKBtuPq3CVe/1o3VOMDHTZXiTNQqzK5evVrffPONPv/8c3Xq1ElWq9Vp/UcffVQnxQEAANSVH/Yd1yXPrtLejAKn5UG+XurfJlwXtg3XhW3C1TzMn5t1JlKrMBsSEqKrrrqqrmsBAACoc56/zap/8ETRb58t6hYbogFtw3VRuybqGhMsL0+m3jerWoXZt99+u06LePnll/X0008rLS1N8fHxevHFF9W7d+8q2w4aNEjffvttpeUjRozQsmXL6rQuAABgfsM7R+vHvScUGeyri9qGq2/rcAX7WU+/IUzhrEYwZ2RkKCUlRZLUvn17NWnSpMb7WLx4sRITEzVv3jz16dNHc+fO1bBhw5SSkqKIiMpztX300UcqLS11fD5+/Lji4+N17bXX1v5EAADAOSs2zF9v3dzL3WWgntTqnnpBQYFuueUWRUdH66KLLtJFF12kpk2b6tZbb1VhYWGN9jVnzhxNmDBB48ePV8eOHTVv3jz5+/tr/vz5VbYPCwtTVFSU42vlypXy9/cnzAIAAJyHanVnNjExUd9++60+/fRT9e/fX9LJh8Luvvtu/eMf/9Crr756RvspLS3Vpk2bNG3aNMcyDw8PDR48WOvWrTujfbz11lv6+9//rkaNGlW5vqSkRCUlJY7Pubm5kiSbzSabzVblNnWp4hiuOBbqB31ofvSh+dGH5nau9195ebmkk28Iq8k52u2Gtqflac2e40o+mKMhF0Toqu5N66vMs+LqPqzJcSyGYRinb+YsPDxcS5Ys0aBBg5yWf/PNN7ruuuuUkZFxRvs5cuSIYmJitHbtWvXt29ex/P7779e3336rH3/88ZTbr1+/Xn369NGPP/5Y7RjbmTNnatasWZWW//e//5W/v/8Z1QkAAFCdn09Y9GaKp+ICDE3pUn7KtpnF0s4ci1JyLNqVY1FB2e+zJjT2MTS9x6m3P18UFhZqzJgxysnJUVBQ0Cnb1urObGFhoSIjIystj4iIqPEwg7Px1ltvqUuXLtUGWUmaNm2aEhMTHZ9zc3MVGxuroUOHnvbi1AWbzaaVK1dqyJAhlaYwgznQh+ZHH5offWhu53r/eW8/pjdTkhUaGqIRI/o4rTteUKof9p7Q2j3HtXbPcR3KLnZa38jHU22aBGjroRz5+PppxIiLXFn6GXN1H1b8Jv1M1CrM9u3bVzNmzNC7774rX19fSVJRUZFmzZrldIf1dMLDw+Xp6an09HSn5enp6YqKijrltgUFBVq0aJEeffTRU7bz8fGRj0/lyY6tVqtLv6FcfTzUPfrQ/OhD86MPze1c7T9PT09JksViUZnhcfJ1uLsztXpXprYddQ5lVk+Lule8DrdNuLo2C9a2I7n668trZLFYGvz1cVUf1uQYtQqzzz//vIYNG6ZmzZopPj5ekrR161b5+vrqiy++OOP9eHt7KyEhQUlJSRo1apQkyW63KykpSZMnTz7lth988IFKSkp044031uYUAAAA6tQvR3IVP+tLlZbbnZZ3iAo8GV7bhqt3XJga+fA63LpUq6vZuXNn7dq1SwsXLtSOHTskSddff71uuOEG+fn51WhfiYmJGjdunHr27KnevXtr7ty5Kigo0Pjx4yVJY8eOVUxMjGbPnu203VtvvaVRo0apcePGtTkFAACAOhHwWzgtLTsZYpsG++pCx+tww9UkkNfh1qda/9PA399fEyZMOOsCRo8erYyMDE2fPl1paWnq1q2bVqxY4RiTm5qaKg8P5xnEUlJStHr1an355ZdnfXwAAICz8ZdWjfXIFR3l7WnRhW2bKK4xr8N1pTMOs0uXLtXw4cNltVq1dOnSU7a98sora1TE5MmTqx1WsGrVqkrL2rdvr1pMwgAAAFDnPDwsuvXClu4u47x1xmF21KhRSktLU0REhGN8a1UsFotjvjUAAACgPp1xmLXb7VX+GQAAAHCXWr3OtirZ2dl1tSsAAADgjNQqzD711FNavHix4/O1116rsLAwxcTEaOvWrXVWHAAAAHAqtQqz8+bNU2xsrCRp5cqV+uqrr7RixQoNHz5c//znP+u0QAAAAKA6tZqaKy0tzRFmP/vsM1133XUaOnSo4uLi1KdPn9NsDQAAANSNWt2ZDQ0N1cGDByVJK1as0ODBgyVJhmEwkwEAAABcplZ3Zq+++mqNGTNGbdu21fHjxzV8+HBJ0pYtW9SmTZs6LRAAAACoTq3C7HPPPae4uDgdPHhQ//73vxUQECBJOnr0qCZOnFinBQIAAJzPim3l+uVwjpo39ldEoK+7y2lwahVmrVar7rvvvkrLp0yZctYFAQAAnM/sdkM70vL0/a4Mrd6dqfX7TqikzK5OTYO07O4B7i6vwWkQr7MFAAA43+UW2XTPoi1asztTmfmlldYfyipyQ1UNH6+zBQAAaADySsr0v+QjkiR/b0/9pVVjXdgmXM1C/XT7fza5ubqGi9fZAgAAuNEF0UHq36ax8kvKNaBNuAa0DVf35qHy9jo56dSejHw3V9iw1WrMLAAAAOqGt5eHFt72F3eXYVq1mmf27rvv1gsvvFBp+UsvvaR77733bGsCAAAAzkitwuyHH36o/v37V1rer18/LVmy5KyLAgAAAM5ErcLs8ePHFRwcXGl5UFCQMjMzz7ooAAAA4EzUKsy2adNGK1asqLT8888/V6tWrc66KAAAAOBM1OoBsMTERE2ePFkZGRm65JJLJElJSUl69tlnNXfu3LqsDwAAAKhWrcLsLbfcopKSEj3++ON67LHHJElxcXF69dVXNXbs2DotEAAAAKhOrafmuuuuu3TXXXcpIyNDfn5+CggIqMu6AAAAgNOq1ZhZSSorK9NXX32ljz76SIZhSJKOHDmi/Hwm9gUAAIBr1OrO7IEDB3TZZZcpNTVVJSUlGjJkiAIDA/XUU0+ppKRE8+bNq+s6AQAAgEpqdWf2nnvuUc+ePZWVlSU/Pz/H8quuukpJSUl1VhwAAABwKrW6M/v9999r7dq18vb2dloeFxenw4cP10lhAAAAwOnU6s6s3W5XeXl5peWHDh1SYGDgWRcFAAAAnIlahdmhQ4c6zSdrsViUn5+vGTNmaMSIEXVVGwAAAHBKtRpm8Mwzz+iyyy5Tx44dVVxcrDFjxmjXrl0KDw/Xe++9V9c1AgAAAFWqVZiNjY3V1q1btXjxYm3dulX5+fm69dZbdcMNNzg9EAYAAADUpxqHWZvNpg4dOuizzz7TDTfcoBtuuKE+6gIAAABOq8ZjZq1Wq4qLi+ujFgAAAKBGavUA2KRJk/TUU0+prKysrusBAAAAzlitxsxu2LBBSUlJ+vLLL9WlSxc1atTIaf1HH31UJ8UBAAAAp1KrMBsSEqJrrrmmrmsBAAAAaqRGYdZut+vpp5/Wzp07VVpaqksuuUQzZ85kBgMAAAC4RY3GzD7++ON68MEHFRAQoJiYGL3wwguaNGlSfdUGAAAAnFKNwuy7776rV155RV988YU++eQTffrpp1q4cKHsdnt91QcAAABUq0ZhNjU11el1tYMHD5bFYtGRI0fqvDAAAADgdGoUZsvKyuTr6+u0zGq1ymaz1WlRAAAAwJmo0QNghmHo5ptvlo+Pj2NZcXGx7rzzTqfpuZiaCwAAAK5QozA7bty4SstuvPHGOisGAAAAqIkahdm33367vuoAAAAAaqxWr7MFAAAAGgLCLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTcnuYffnllxUXFydfX1/16dNH69evP2X77OxsTZo0SdHR0fLx8VG7du20fPlyF1ULAACAhsTLnQdfvHixEhMTNW/ePPXp00dz587VsGHDlJKSooiIiErtS0tLNWTIEEVERGjJkiWKiYnRgQMHFBIS4vriAQAA4HZuDbNz5szRhAkTNH78eEnSvHnztGzZMs2fP19Tp06t1H7+/Pk6ceKE1q5dK6vVKkmKi4tzZckAAABoQNwWZktLS7Vp0yZNmzbNsczDw0ODBw/WunXrqtxm6dKl6tu3ryZNmqT//e9/atKkicaMGaMHHnhAnp6eVW5TUlKikpISx+fc3FxJks1mk81mq8MzqlrFMVxxLNQP+tD86EPzow/Njf47O2W2st/+ZLjtGrq6D2tyHLeF2czMTJWXlysyMtJpeWRkpHbs2FHlNnv37tXXX3+tG264QcuXL9fu3bs1ceJE2Ww2zZgxo8ptZs+erVmzZlVa/uWXX8rf3//sT+QMrVy50mXHQv2gD82PPjQ/+tDc6L/aSS+SJC/ZSm1uf07IVX1YWFh4xm3dOsygpux2uyIiIvT666/L09NTCQkJOnz4sJ5++ulqw+y0adOUmJjo+Jybm6vY2FgNHTpUQUFB9V6zzWbTypUrNWTIEMfQCJgLfWh+9KH50YfmRv+dnb0ZBXoieY2s3laNGDHMLTW4ug8rfpN+JtwWZsPDw+Xp6an09HSn5enp6YqKiqpym+joaFmtVqchBRdccIHS0tJUWloqb2/vStv4+PjIx8en0nKr1erSbyhXHw91jz40P/rQ/OhDc6P/asfLWhHXLG6/fq7qw5ocw21Tc3l7eyshIUFJSUmOZXa7XUlJSerbt2+V2/Tv31+7d++W3W53LNu5c6eio6OrDLIAAAA4t7l1ntnExES98cYbeuedd7R9+3bdddddKigocMxuMHbsWKcHxO666y6dOHFC99xzj3bu3Klly5bpiSee0KRJk9x1CgAAAHAjt46ZHT16tDIyMjR9+nSlpaWpW7duWrFiheOhsNTUVHl4/J63Y2Nj9cUXX2jKlCnq2rWrYmJidM899+iBBx5w1ykAAADAjdz+ANjkyZM1efLkKtetWrWq0rK+ffvqhx9+qOeqAAAAYAZuf50tAAAAUFuEWQAAAJgWYRYAAACmRZgFAACAaRFmAQAAYFqEWQAAAJgWYRYAAACmRZgFAACAaRFmAQAAYFqEWQAAAJgWYRYAAACmRZgFAACAaRFmAQAAYFqEWQAAAJgWYRYAAACmRZgFAACAaRFmAQAAYFqEWQAAAJgWYRYAAACm5eXuAgAAAFBztnK7Nuw/oa+3H9Pq3Zn6S6vGmnllJ3eX5XKEWQAAAJPIKijVqp3H9NX2Y/ouJUN5JWWOdbuP5RNmAQAA0DDlFNmU8K+Vshu/L2vcyFu94sK04tc09xXmZoRZAACABizAx0sWi2QYkt2QLogO0qUdInTpBRGKbxaijPwSwiwAAAAapsggX708poeyCkt1cfsINQ3xc3dJDQphFgAAoIEb0SXa3SU0WEzNBQAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANNqEGH25ZdfVlxcnHx9fdWnTx+tX7++2rYLFiyQxWJx+vL19XVhtQAAAGgo3B5mFy9erMTERM2YMUObN29WfHy8hg0bpmPHjlW7TVBQkI4ePer4OnDggAsrBgAAQEPh9jA7Z84cTZgwQePHj1fHjh01b948+fv7a/78+dVuY7FYFBUV5fiKjIx0YcUAAABoKLzcefDS0lJt2rRJ06ZNcyzz8PDQ4MGDtW7dumq3y8/PV4sWLWS329WjRw898cQT6tSpU5VtS0pKVFJS4vicm5srSbLZbLLZbHV0JtWrOIYrjoX6QR+aH31ofvShudF/9euP17W+rrGr+7Amx3FrmM3MzFR5eXmlO6uRkZHasWNHldu0b99e8+fPV9euXZWTk6NnnnlG/fr106+//qpmzZpVaj979mzNmjWr0vIvv/xS/v7+dXMiZ2DlypUuOxbqB31ofvSh+dGH5kb/1Y+cUknykt2wa/ny5fV6LFf1YWFh4Rm3dWuYrY2+ffuqb9++js/9+vXTBRdcoNdee02PPfZYpfbTpk1TYmKi43Nubq5iY2M1dOhQBQUF1Xu9NptNK1eu1JAhQ2S1Wuv9eKh79KH50YfmRx+aG/1Xv9JzizV903fysHhoxIhh9XIMV/dhxW/Sz4Rbw2x4eLg8PT2Vnp7utDw9PV1RUVFntA+r1aru3btr9+7dVa738fGRj49Pldu58hvK1cdD3aMPzY8+ND/60Nzov/phtZb/4c/1e31d1Yc1OYZbHwDz9vZWQkKCkpKSHMvsdruSkpKc7r6eSnl5uX7++WdFR0fXV5kAAABooNw+zCAxMVHjxo1Tz5491bt3b82dO1cFBQUaP368JGns2LGKiYnR7NmzJUmPPvqo/vKXv6hNmzbKzs7W008/rQMHDui2225z52kAAADADdweZkePHq2MjAxNnz5daWlp6tatm1asWOF4KCw1NVUeHr/fQM7KytKECROUlpam0NBQJSQkaO3aterYsaO7TgEAAABu4vYwK0mTJ0/W5MmTq1y3atUqp8/PPfecnnvuORdUBQAAgIbO7S9NAAAAAGqLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtLzcXQAAAADqV0FJmXytnvL0sDgtNwxDu47l67udGWoW6q/LOke5qcLaI8wCAACcYypCatL2Y/pmxzFtSs1SmyYB+vyeASops2vtnkx9k3JM3+zI0OHsIkmSl4dFW6YPUaCv1c3V1wxhFgAA4BxgSPpmxzF9/dtXRUitkJKep7Hz12v9/hMqLbM7lnt7eai0zK4yu6GSMrsCXVz32SLMAgAAnAPK7YbGL9jg+Ozt5aF+rRurf+twPb58uyRp9e5MSVJMiJ8u6RChizs0Ud9W4bpg+gq31FwXCLMAAAAmFuRrVbCfVTlFNkUH++riDhG6pH2E+rVpLH/vk1HvWF6xdqTlaUDbcF3cPkJtIgJksVhOs2dzIMwCAACYmJ+3p1bcO0C5RWVqF1l1SH3o8o5uqMw1CLMAAAAmFx3sp+hgd1fhHswzCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAOCUim3lshvurqJqXu4uAAAAAA2LYRhKSc/TtykZ+m5XhtbvOyF/T08NHlouq9Xq7vKcEGYBAAAgSfr8lzRtPZit73dlKD23xGldTrlF6XklCvT3dVN1VWsQwwxefvllxcXFydfXV3369NH69evPaLtFixbJYrFo1KhR9VsgAADAeeCRT37Rkk2HlJ5bIl+rhwa1b6IZIzvK19ogImOV3H5ndvHixUpMTNS8efPUp08fzZ07V8OGDVNKSooiIiKq3W7//v267777NGDAABdWCwAAcO7pEBWoHWl5ah8ZqIHtm+iitk3UMy5UvlZPSdIzX6a4ucLquT3MzpkzRxMmTND48eMlSfPmzdOyZcs0f/58TZ06tcptysvLdcMNN2jWrFn6/vvvlZ2dXe3+S0pKVFLy+23y3NxcSZLNZpPNZqu7E6lGxTFccSzUD/rQ/OhD86MPzY3+a/g+vKOP8krK1LiR9x+W2mWz2U/+8beHv8psZS7NT2fCrWG2tLRUmzZt0rRp0xzLPDw8NHjwYK1bt67a7R599FFFRETo1ltv1ffff3/KY8yePVuzZs2qtPzLL7+Uv79/7YuvoZUrV7rsWKgf9KH50YfmRx+aG/1nXmXlnpIsWrNmtVJcMGS2sLDwjNu6NcxmZmaqvLxckZGRTssjIyO1Y8eOKrdZvXq13nrrLSUnJ5/RMaZNm6bExETH59zcXMXGxmro0KEKCgqqde1nymazaeXKlRoyZEiDe/oPZ4Y+ND/60PzoQ3Oj/8zvwU1JKikvV//+F6p1ZP3np4rfpJ8Jtw8zqIm8vDzddNNNeuONNxQeHn5G2/j4+MjHx6fScqvV6tJvKFcfD3WPPjQ/+tD86ENzo/9MzHLyP15WL5f0YU2O4dYwGx4eLk9PT6WnpzstT09PV1RUVKX2e/bs0f79+zVy5EjHMrv95FgOLy8vpaSkqHXr1vVbNAAAABoMt86z4O3trYSEBCUlJTmW2e12JSUlqW/fvpXad+jQQT///LOSk5MdX1deeaUuvvhiJScnKzY21pXlAwAAwM3cPswgMTFR48aNU8+ePdW7d2/NnTtXBQUFjtkNxo4dq5iYGM2ePVu+vr7q3Lmz0/YhISGSVGk5AAAAzn1uD7OjR49WRkaGpk+frrS0NHXr1k0rVqxwPBSWmpoqD4+GO1EvAAAA3MftYVaSJk+erMmTJ1e5btWqVafcdsGCBXVfEAAAAEyBW54AAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATqlbsxC1DDTk49XwomPDqwgAAAANyoKbE3Rv53JFBfm6u5RKCLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATMvL3QW4mmEYkqTc3FyXHM9ms6mwsFC5ubmyWq0uOSbqFn1ofvSh+dGH5kb/mZ+r+7Aip1XktlM578JsXl6eJCk2NtbNlQAAAOBU8vLyFBwcfMo2FuNMIu85xG6368iRIwoMDJTFYqn34+Xm5io2NlYHDx5UUFBQvR8PdY8+ND/60PzoQ3Oj/8zP1X1oGIby8vLUtGlTeXicelTseXdn1sPDQ82aNXP5cYOCgvgGNjn60PzoQ/OjD82N/jM/V/bh6e7IVuABMAAAAJgWYRYAAACmRZitZz4+PpoxY4Z8fHzcXQpqiT40P/rQ/OhDc6P/zK8h9+F59wAYAAAAzh3cmQUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmK0DL7/8suLi4uTr66s+ffpo/fr1p2z/wQcfqEOHDvL19VWXLl20fPlyF1WK6tSkD9944w0NGDBAoaGhCg0N1eDBg0/b56h/Nf0+rLBo0SJZLBaNGjWqfgvEadW0D7OzszVp0iRFR0fLx8dH7dq14+epG9W0/+bOnav27dvLz89PsbGxmjJlioqLi11ULf7su+++08iRI9W0aVNZLBZ98sknp91m1apV6tGjh3x8fNSmTRstWLCg3uuskoGzsmjRIsPb29uYP3++8euvvxoTJkwwQkJCjPT09Crbr1mzxvD09DT+/e9/G9u2bTMefvhhw2q1Gj///LOLK0eFmvbhmDFjjJdfftnYsmWLsX37duPmm282goODjUOHDrm4clSoaR9W2LdvnxETE2MMGDDA+Otf/+qaYlGlmvZhSUmJ0bNnT2PEiBHG6tWrjX379hmrVq0ykpOTXVw5DKPm/bdw4ULDx8fHWLhwobFv3z7jiy++MKKjo40pU6a4uHJUWL58ufHQQw8ZH330kSHJ+Pjjj0/Zfu/evYa/v7+RmJhobNu2zXjxxRcNT09PY8WKFa4p+A8Is2epd+/exqRJkxyfy8vLjaZNmxqzZ8+usv11111nXH755U7L+vTpY9xxxx31WieqV9M+/LOysjIjMDDQeOedd+qrRJxGbfqwrKzM6Nevn/Hmm28a48aNI8y6WU378NVXXzVatWpllJaWuqpEnEJN+2/SpEnGJZdc4rQsMTHR6N+/f73WiTNzJmH2/vvvNzp16uS0bPTo0cawYcPqsbKqMczgLJSWlmrTpk0aPHiwY5mHh4cGDx6sdevWVbnNunXrnNpL0rBhw6ptj/pVmz78s8LCQtlsNoWFhdVXmTiF2vbho48+qoiICN16662uKBOnUJs+XLp0qfr27atJkyYpMjJSnTt31hNPPKHy8nJXlY3f1Kb/+vXrp02bNjmGIuzdu1fLly/XiBEjXFIzzl5DyjNeLj/iOSQzM1Pl5eWKjIx0Wh4ZGakdO3ZUuU1aWlqV7dPS0uqtTlSvNn34Zw888ICaNm1a6ZsarlGbPly9erXeeustJScnu6BCnE5t+nDv3r36+uuvdcMNN2j58uXavXu3Jk6cKJvNphkzZriibPymNv03ZswYZWZm6sILL5RhGCorK9Odd96pBx980BUlow5Ul2dyc3NVVFQkPz8/l9XCnVngLDz55JNatGiRPv74Y/n6+rq7HJyBvLw83XTTTXrjjTcUHh7u7nJQS3a7XREREXr99deVkJCg0aNH66GHHtK8efPcXRrOwKpVq/TEE0/olVde0ebNm/XRRx9p2bJleuyxx9xdGkyIO7NnITw8XJ6enkpPT3danp6erqioqCq3iYqKqlF71K/a9GGFZ555Rk8++aS++uorde3atT7LxCnUtA/37Nmj/fv3a+TIkY5ldrtdkuTl5aWUlBS1bt26fouGk9p8H0ZHR8tqtcrT09Ox7IILLlBaWppKS0vl7e1drzXjd7Xpv0ceeUQ33XSTbrvtNklSly5dVFBQoNtvv10PPfSQPDy419bQVZdngoKCXHpXVuLO7Fnx9vZWQkKCkpKSHMvsdruSkpLUt2/fKrfp27evU3tJWrlyZbXtUb9q04eS9O9//1uPPfaYVqxYoZ49e7qiVFSjpn3YoUMH/fzzz0pOTnZ8XXnllbr44ouVnJys2NhYV5YP1e77sH///tq9e7fjHyKStHPnTkVHRxNkXaw2/VdYWFgpsFb8w8QwjPorFnWmQeUZlz9ydo5ZtGiR4ePjYyxYsMDYtm2bcfvttxshISFGWlqaYRiGcdNNNxlTp051tF+zZo3h5eVlPPPMM8b27duNGTNmMDWXm9W0D5988knD29vbWLJkiXH06FHHV15enrtO4bxX0z78M2YzcL+a9mFqaqoRGBhoTJ482UhJSTE+++wzIyIiwvjXv/7lrlM4r9W0/2bMmGEEBgYa7733nrF3717jyy+/NFq3bm1cd9117jqF815eXp6xZcsWY8uWLYYkY86cOcaWLVuMAwcOGIZhGFOnTjVuuukmR/uKqbn++c9/Gtu3bzdefvllpuYysxdffNFo3ry54e3tbfTu3dv44YcfHOsGDhxojBs3zqn9+++/b7Rr187w9vY2OnXqZCxbtszFFePPatKHLVq0MCRV+poxY4brC4dDTb8P/4gw2zDUtA/Xrl1r9OnTx/Dx8TFatWplPP7440ZZWZmLq0aFmvSfzWYzZs6cabRu3drw9fU1YmNjjYkTJxpZWVmuLxyGYRjGN998U+XfbRX9Nm7cOGPgwIGVtunWrZvh7e1ttGrVynj77bddXrdhGIbFMLifDwAAAHNizCwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAnMcsFos++eQTSdL+/ftlsViUnJzs1poAoCYIswDgJjfffLMsFossFousVqtatmyp+++/X8XFxe4uDQBMw8vdBQDA+eyyyy7T22+/LZvNpk2bNmncuHGyWCx66qmn3F0aAJgCd2YBwI18fHwUFRWl2NhYjRo1SoMHD9bKlSslSXa7XbNnz1bLli3l5+en+Ph4LVmyxGn7X3/9VVdccYWCgoIUGBioAQMGaM+ePZKkDRs2aMiQIQoPD1dwcLAGDhyozZs3u/wcAaA+EWYBoIH45ZdftHbtWnl7e0uSZs+erXfffVfz5s3Tr7/+qilTpujGG2/Ut99+K0k6fPiwLrroIvn4+Ojrr7/Wpk2bdMstt6isrEySlJeXp3Hjxmn16tX64Ycf1LZtW40YMUJ5eXluO0cAqGsMMwAAN/rss88UEBCgsrIylZSUyMPDQy+99JJKSkr0xBNP6KuvvlLfvn0lSa1atdLq1av12muvaeDAgXr55ZcVHBysRYsWyWq1SpLatWvn2Pcll1zidKzXX39dISEh+vbbb3XFFVe47iQBoB4RZgHAjS6++GK9+uqrKigo0HPPPScvLy9dc801+vXXX1VYWKghQ4Y4tS8tLVX37t0lScnJyRowYIAjyP5Zenq6Hn74Ya1atUrHjh1TeXm5CgsLlZqaWu/nBQCuQpgFADdq1KiR2rRpI0maP3++4uPj9dZbb6lz586SpGXLlikmJsZpGx8fH0mSn5/fKfc9btw4HT9+XM8//7xatGghHx8f9e3bV6WlpfVwJgDgHoRZAGggPDw89OCDDyoxMVE7d+6Uj4+PUlNTNXDgwCrbd+3aVe+8845sNluVd2fXrFmjV155RSNGjJAkHTx4UJmZmfV6DgDgajwABgANyLXXXitPT0+99tpruu+++zRlyhS988472rNnjzZv3qwXX3xR77zzjiRp8uTJys3N1d///ndt3LhRu3bt0n/+8x+lpKRIktq2bav//Oc/2r59u3788UfdcMMNp72bCwBmw51ZAGhAvLy8NHnyZP373//Wvn371KRJE82ePVt79+5VSEiIevTooQcffFCS1LhxY3399df65z//qYEDB8rT01PdunVT//79JUlvvfWWbr/9dvXo0UOxsbF64okndN9997nz9ACgzlkMwzDcXQQAAABQGwwzAAAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACY1v8HW9Iuc9LE39gAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#21)  Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# List of solvers to compare\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "\n",
        "# Dictionary to store accuracy results\n",
        "accuracies = {}\n",
        "\n",
        "for solver in solvers:\n",
        "    # Note: 'liblinear' does not support multinomial, so use 'ovr' for multi_class there\n",
        "    if solver == 'liblinear':\n",
        "        model = LogisticRegression(solver=solver, multi_class='ovr', max_iter=500)\n",
        "    else:\n",
        "        model = LogisticRegression(solver=solver, multi_class='multinomial', max_iter=500)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    accuracies[solver] = acc\n",
        "\n",
        "# Print the accuracy for each solver\n",
        "for solver, acc in accuracies.items():\n",
        "    print(f\"Accuracy with solver '{solver}': {acc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyERHgYnVKxy",
        "outputId": "cf54a855-1b03-4f10-fd9a-7cf3c1e72638"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with solver 'liblinear': 1.000\n",
            "Accuracy with solver 'saga': 1.000\n",
            "Accuracy with solver 'lbfgs': 1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#22) Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC)\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# Load dataset and keep only two classes for binary classification\n",
        "data = load_iris()\n",
        "X = data.data[data.target != 2]\n",
        "y = data.target[data.target != 2]\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=500, solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Matthews Correlation Coefficient\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHTOkUtmVWca",
        "outputId": "df060c22-3bf5-4b95-af44-0204f0b2b0b8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient (MCC): 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#23) Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1) Logistic Regression on raw data\n",
        "model_raw = LogisticRegression(max_iter=500, solver='lbfgs', multi_class='auto')\n",
        "model_raw.fit(X_train, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "acc_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "# 2) Logistic Regression on standardized data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=500, solver='lbfgs', multi_class='auto')\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "acc_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Print accuracies\n",
        "print(f\"Accuracy on raw data: {acc_raw:.3f}\")\n",
        "print(f\"Accuracy on standardized data: {acc_scaled:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IK6VEYqjVq55",
        "outputId": "320476ba-ab38-4ebc-b04d-6d031c62fd70"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on raw data: 1.000\n",
            "Accuracy on standardized data: 1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#24) Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression model (no need to specify C here)\n",
        "model = LogisticRegression(max_iter=500, solver='lbfgs', multi_class='auto')\n",
        "\n",
        "# Define grid of C values to test\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Setup GridSearchCV with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit GridSearchCV on training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best C found\n",
        "best_C = grid_search.best_params_['C']\n",
        "print(f\"Optimal C (regularization strength): {best_C}\")\n",
        "\n",
        "# Evaluate the best model on test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test set accuracy with optimal C: {accuracy:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBz4cdtrVxdC",
        "outputId": "f08a2d9a-758c-4452-b90d-0a021af50609"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal C (regularization strength): 1\n",
            "Test set accuracy with optimal C: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#25)  Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=500, solver='lbfgs', multi_class='auto')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model to a file\n",
        "model_filename = 'logistic_model.joblib'\n",
        "joblib.dump(model, model_filename)\n",
        "print(f\"Model saved to {model_filename}\")\n",
        "\n",
        "# Load the model from file\n",
        "loaded_model = joblib.load(model_filename)\n",
        "print(\"Model loaded from file.\")\n",
        "\n",
        "# Make predictions with the loaded model\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of loaded model: {accuracy:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlHM2v1RV6YC",
        "outputId": "8f0d8904-4a36-4a47-8607-febdd7b43c2d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to logistic_model.joblib\n",
            "Model loaded from file.\n",
            "Accuracy of loaded model: 1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9-rp8jbYWGQU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}